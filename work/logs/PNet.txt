loading data...
source domain:  books target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 11843
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
5600 400 6000 15750 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.39541829, sen-loss: 77.05432564, dom-loss: 81.34109193, train-acc: 0.67892857, val-acc: 0.68500000 val_loss: 0.65902936, dom-acc: 0.77160714
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 146.63717198, sen-loss: 70.73615777, dom-loss: 75.90101451, train-acc: 0.75732143, val-acc: 0.79250000 val_loss: 0.59347957, dom-acc: 0.80017857
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 136.88947761, sen-loss: 61.82541096, dom-loss: 75.06406671, train-acc: 0.81500000, val-acc: 0.81500000 val_loss: 0.50043726, dom-acc: 0.74651786
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 126.23064399, sen-loss: 51.28667456, dom-loss: 74.94396943, train-acc: 0.85214286, val-acc: 0.85000000 val_loss: 0.40629584, dom-acc: 0.68375000
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 117.01018280, sen-loss: 42.04637593, dom-loss: 74.96380693, train-acc: 0.87017857, val-acc: 0.87000000 val_loss: 0.35628918, dom-acc: 0.65535714
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 112.40805835, sen-loss: 37.09000812, dom-loss: 75.31805044, train-acc: 0.87446429, val-acc: 0.87250000 val_loss: 0.34377727, dom-acc: 0.70785714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.77587163, sen-loss: 35.26747723, dom-loss: 75.50839454, train-acc: 0.87928571, val-acc: 0.88000000 val_loss: 0.34190425, dom-acc: 0.70544643
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.04746664, sen-loss: 34.21939777, dom-loss: 75.82806855, train-acc: 0.88446429, val-acc: 0.87500000 val_loss: 0.33196807, dom-acc: 0.69955357
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.56714612, sen-loss: 33.56949235, dom-loss: 75.99765366, train-acc: 0.88071429, val-acc: 0.88000000 val_loss: 0.34637505, dom-acc: 0.70732143
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.02827728, sen-loss: 32.76248012, dom-loss: 76.26579726, train-acc: 0.88857143, val-acc: 0.88250000 val_loss: 0.32903945, dom-acc: 0.69285714
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 109.15040839, sen-loss: 32.41193891, dom-loss: 76.73846930, train-acc: 0.89178571, val-acc: 0.88750000 val_loss: 0.32058910, dom-acc: 0.67875000
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.55277604, sen-loss: 31.54069500, dom-loss: 77.01208103, train-acc: 0.89303571, val-acc: 0.89250000 val_loss: 0.31771204, dom-acc: 0.67258929
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.41954911, sen-loss: 31.21227141, dom-loss: 77.20727730, train-acc: 0.89446429, val-acc: 0.88500000 val_loss: 0.32251063, dom-acc: 0.67696429
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.08398992, sen-loss: 30.63881564, dom-loss: 77.44517446, train-acc: 0.89750000, val-acc: 0.89500000 val_loss: 0.31476593, dom-acc: 0.64848214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 107.87969750, sen-loss: 30.20346390, dom-loss: 77.67623347, train-acc: 0.89892857, val-acc: 0.89250000 val_loss: 0.31157097, dom-acc: 0.65053571
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 107.69555271, sen-loss: 29.76228614, dom-loss: 77.93326676, train-acc: 0.90125000, val-acc: 0.89500000 val_loss: 0.31079021, dom-acc: 0.64937500
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.53530234, sen-loss: 29.40958146, dom-loss: 78.12572098, train-acc: 0.90285714, val-acc: 0.89250000 val_loss: 0.31167099, dom-acc: 0.63982143
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.38370341, sen-loss: 29.20021925, dom-loss: 78.18348402, train-acc: 0.90357143, val-acc: 0.89500000 val_loss: 0.30765685, dom-acc: 0.63982143
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.20621771, sen-loss: 28.69890145, dom-loss: 78.50731635, train-acc: 0.90678571, val-acc: 0.89250000 val_loss: 0.30660754, dom-acc: 0.61410714
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.87522274, sen-loss: 28.30972225, dom-loss: 78.56550115, train-acc: 0.90678571, val-acc: 0.89250000 val_loss: 0.30672160, dom-acc: 0.60267857
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 106.82731587, sen-loss: 28.11162747, dom-loss: 78.71568865, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.30394801, dom-acc: 0.60633929
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 106.51435125, sen-loss: 27.86099381, dom-loss: 78.65335721, train-acc: 0.90982143, val-acc: 0.89250000 val_loss: 0.30324152, dom-acc: 0.60883929
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 106.27986169, sen-loss: 27.47192574, dom-loss: 78.80793595, train-acc: 0.91017857, val-acc: 0.89250000 val_loss: 0.30305451, dom-acc: 0.60464286
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.31361663, sen-loss: 27.38318824, dom-loss: 78.93042845, train-acc: 0.91125000, val-acc: 0.89750000 val_loss: 0.30067617, dom-acc: 0.58187500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 105.62095207, sen-loss: 26.83540906, dom-loss: 78.78554308, train-acc: 0.91214286, val-acc: 0.89500000 val_loss: 0.29993811, dom-acc: 0.59044643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 105.33621132, sen-loss: 26.65584417, dom-loss: 78.68036723, train-acc: 0.91303571, val-acc: 0.89250000 val_loss: 0.30458856, dom-acc: 0.59500000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 105.30789495, sen-loss: 26.41822135, dom-loss: 78.88967359, train-acc: 0.91303571, val-acc: 0.89500000 val_loss: 0.29793316, dom-acc: 0.59830357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 104.87893271, sen-loss: 26.26738003, dom-loss: 78.61155331, train-acc: 0.91625000, val-acc: 0.89000000 val_loss: 0.29683256, dom-acc: 0.59750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 104.54292554, sen-loss: 25.88288215, dom-loss: 78.66004348, train-acc: 0.91464286, val-acc: 0.89500000 val_loss: 0.29565406, dom-acc: 0.58794643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 104.20175910, sen-loss: 25.61241426, dom-loss: 78.58934510, train-acc: 0.91589286, val-acc: 0.89500000 val_loss: 0.29503515, dom-acc: 0.58776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.81772649, sen-loss: 25.37929020, dom-loss: 78.43843627, train-acc: 0.91750000, val-acc: 0.89000000 val_loss: 0.30182704, dom-acc: 0.60758929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 103.33183795, sen-loss: 24.98503663, dom-loss: 78.34680098, train-acc: 0.91767857, val-acc: 0.89750000 val_loss: 0.29407373, dom-acc: 0.59633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 103.10220659, sen-loss: 24.77362080, dom-loss: 78.32858557, train-acc: 0.92125000, val-acc: 0.89250000 val_loss: 0.29316872, dom-acc: 0.61883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.67697299, sen-loss: 24.63069445, dom-loss: 78.04627860, train-acc: 0.92125000, val-acc: 0.89500000 val_loss: 0.29256177, dom-acc: 0.62955357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.31354272, sen-loss: 24.33338866, dom-loss: 77.98015416, train-acc: 0.92142857, val-acc: 0.90000000 val_loss: 0.29061806, dom-acc: 0.64250000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.13598037, sen-loss: 24.17637357, dom-loss: 77.95960695, train-acc: 0.92285714, val-acc: 0.89500000 val_loss: 0.29195878, dom-acc: 0.61000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.53924304, sen-loss: 23.83004111, dom-loss: 77.70920169, train-acc: 0.92250000, val-acc: 0.89250000 val_loss: 0.30014870, dom-acc: 0.64482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 101.16804999, sen-loss: 23.51097313, dom-loss: 77.65707684, train-acc: 0.92303571, val-acc: 0.89500000 val_loss: 0.29130432, dom-acc: 0.63598214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.82888532, sen-loss: 23.20549156, dom-loss: 77.62339401, train-acc: 0.92500000, val-acc: 0.89500000 val_loss: 0.29103446, dom-acc: 0.64357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.84766173, sen-loss: 23.32748800, dom-loss: 77.52017373, train-acc: 0.92589286, val-acc: 0.89750000 val_loss: 0.29038328, dom-acc: 0.64357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 100.12953347, sen-loss: 22.73100351, dom-loss: 77.39852989, train-acc: 0.92821429, val-acc: 0.89500000 val_loss: 0.29173496, dom-acc: 0.65285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.67825139, sen-loss: 22.42600854, dom-loss: 77.25224316, train-acc: 0.92714286, val-acc: 0.90000000 val_loss: 0.29028511, dom-acc: 0.65866071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 99.30800545, sen-loss: 22.09858269, dom-loss: 77.20942259, train-acc: 0.93089286, val-acc: 0.89500000 val_loss: 0.29049250, dom-acc: 0.66883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [44 ] loss: 99.06811136, sen-loss: 21.92724445, dom-loss: 77.14086699, train-acc: 0.93053571, val-acc: 0.89500000 val_loss: 0.29395536, dom-acc: 0.66678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [45 ] loss: 98.84402496, sen-loss: 21.77720778, dom-loss: 77.06681728, train-acc: 0.93285714, val-acc: 0.89000000 val_loss: 0.29681316, dom-acc: 0.65892857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [46 ] loss: 98.54548615, sen-loss: 21.46795566, dom-loss: 77.07753050, train-acc: 0.93339286, val-acc: 0.89250000 val_loss: 0.29664931, dom-acc: 0.66937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [47 ] loss: 98.31288975, sen-loss: 21.18784048, dom-loss: 77.12504929, train-acc: 0.93232143, val-acc: 0.89500000 val_loss: 0.29244614, dom-acc: 0.66392857
---------------------------------------------------

Successfully load model from save path: ./work/models/books_dvd_PNet.ckpt
Best Epoch: [ 42] best val accuracy: 0.00000000 best val loss: 0.29028511
Testing accuracy: 0.87216667
./work/attentions/books_dvd_train.txt
./work/pivots/books_dvd_pos.txt
./work/pivots/books_dvd_neg.txt
./work/attentions/books_dvd_test.txt
loading data...
source domain:  books target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 17009
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
5600 400 6000 15750 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.47965133, sen-loss: 77.02578890, dom-loss: 82.45386320, train-acc: 0.68017857, val-acc: 0.67500000 val_loss: 0.65861726, dom-acc: 0.81133929
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 145.70526743, sen-loss: 70.69662118, dom-loss: 75.00864661, train-acc: 0.75607143, val-acc: 0.77500000 val_loss: 0.59332007, dom-acc: 0.88133929
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 135.00784540, sen-loss: 61.80851507, dom-loss: 73.19933069, train-acc: 0.81535714, val-acc: 0.81000000 val_loss: 0.50118887, dom-acc: 0.81919643
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 124.40889943, sen-loss: 51.36653012, dom-loss: 73.04236907, train-acc: 0.85232143, val-acc: 0.84750000 val_loss: 0.40814656, dom-acc: 0.74580357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.86517680, sen-loss: 42.11083938, dom-loss: 73.75433761, train-acc: 0.87071429, val-acc: 0.87000000 val_loss: 0.35752711, dom-acc: 0.72589286
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.57470614, sen-loss: 36.99806771, dom-loss: 74.57663858, train-acc: 0.87875000, val-acc: 0.87250000 val_loss: 0.34420031, dom-acc: 0.72767857
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.81868315, sen-loss: 35.18280517, dom-loss: 75.63587809, train-acc: 0.88071429, val-acc: 0.88250000 val_loss: 0.34264868, dom-acc: 0.70464286
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.91074288, sen-loss: 34.13146406, dom-loss: 76.77927887, train-acc: 0.88553571, val-acc: 0.87750000 val_loss: 0.33207780, dom-acc: 0.68107143
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.94131285, sen-loss: 33.49803571, dom-loss: 77.44327730, train-acc: 0.88071429, val-acc: 0.88250000 val_loss: 0.34804893, dom-acc: 0.65883929
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.93871689, sen-loss: 32.68732110, dom-loss: 78.25139570, train-acc: 0.88839286, val-acc: 0.88250000 val_loss: 0.32980317, dom-acc: 0.63303571
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.10634917, sen-loss: 32.36084256, dom-loss: 78.74550647, train-acc: 0.89178571, val-acc: 0.88500000 val_loss: 0.32049909, dom-acc: 0.57482143
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.61249721, sen-loss: 31.48285301, dom-loss: 79.12964427, train-acc: 0.89500000, val-acc: 0.89000000 val_loss: 0.31772590, dom-acc: 0.57339286
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.34275991, sen-loss: 31.16600777, dom-loss: 79.17675221, train-acc: 0.89446429, val-acc: 0.88500000 val_loss: 0.32361734, dom-acc: 0.58107143
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 109.81948876, sen-loss: 30.57575354, dom-loss: 79.24373502, train-acc: 0.89785714, val-acc: 0.89250000 val_loss: 0.31494603, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.12522364, sen-loss: 30.14643799, dom-loss: 78.97878551, train-acc: 0.90017857, val-acc: 0.89250000 val_loss: 0.31142464, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.46229136, sen-loss: 29.70568497, dom-loss: 78.75660628, train-acc: 0.90178571, val-acc: 0.89000000 val_loss: 0.31110299, dom-acc: 0.60008929
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.92830241, sen-loss: 29.33958787, dom-loss: 78.58871490, train-acc: 0.90196429, val-acc: 0.89250000 val_loss: 0.31334642, dom-acc: 0.60241071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.33273196, sen-loss: 29.14380522, dom-loss: 78.18892688, train-acc: 0.90482143, val-acc: 0.89250000 val_loss: 0.30821937, dom-acc: 0.61848214
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.75122094, sen-loss: 28.64074390, dom-loss: 78.11047739, train-acc: 0.90571429, val-acc: 0.89000000 val_loss: 0.30779466, dom-acc: 0.59580357
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.15322948, sen-loss: 28.24433811, dom-loss: 77.90889132, train-acc: 0.90839286, val-acc: 0.89000000 val_loss: 0.30775952, dom-acc: 0.61062500
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 105.74595344, sen-loss: 28.03257828, dom-loss: 77.71337515, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.30514434, dom-acc: 0.62714286
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 105.30418497, sen-loss: 27.79750447, dom-loss: 77.50668085, train-acc: 0.91035714, val-acc: 0.89500000 val_loss: 0.30474919, dom-acc: 0.63776786
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 104.95905966, sen-loss: 27.40162256, dom-loss: 77.55743730, train-acc: 0.91125000, val-acc: 0.89500000 val_loss: 0.30457282, dom-acc: 0.62437500
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 104.99936324, sen-loss: 27.34949578, dom-loss: 77.64986730, train-acc: 0.91214286, val-acc: 0.89000000 val_loss: 0.30220267, dom-acc: 0.61580357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.32081097, sen-loss: 26.76114231, dom-loss: 77.55966854, train-acc: 0.91303571, val-acc: 0.88750000 val_loss: 0.30149025, dom-acc: 0.62330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 104.21574312, sen-loss: 26.58700608, dom-loss: 77.62873709, train-acc: 0.91321429, val-acc: 0.89000000 val_loss: 0.30779359, dom-acc: 0.59410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 104.04148030, sen-loss: 26.34172547, dom-loss: 77.69975519, train-acc: 0.91446429, val-acc: 0.88500000 val_loss: 0.29976329, dom-acc: 0.63241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 103.89846790, sen-loss: 26.18514132, dom-loss: 77.71332622, train-acc: 0.91678571, val-acc: 0.89000000 val_loss: 0.29930094, dom-acc: 0.60955357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 103.55504787, sen-loss: 25.79823180, dom-loss: 77.75681627, train-acc: 0.91714286, val-acc: 0.88500000 val_loss: 0.29818410, dom-acc: 0.60107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 103.46384931, sen-loss: 25.53288857, dom-loss: 77.93096071, train-acc: 0.91696429, val-acc: 0.88750000 val_loss: 0.29766348, dom-acc: 0.60348214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.12156701, sen-loss: 25.29981170, dom-loss: 77.82175553, train-acc: 0.91678571, val-acc: 0.89000000 val_loss: 0.30656382, dom-acc: 0.61196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.76265061, sen-loss: 24.88824908, dom-loss: 77.87440157, train-acc: 0.92053571, val-acc: 0.88750000 val_loss: 0.29726997, dom-acc: 0.60482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.55097413, sen-loss: 24.68740954, dom-loss: 77.86356503, train-acc: 0.92107143, val-acc: 0.89250000 val_loss: 0.29713887, dom-acc: 0.61633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.24648780, sen-loss: 24.52727019, dom-loss: 77.71921772, train-acc: 0.92178571, val-acc: 0.89250000 val_loss: 0.29666376, dom-acc: 0.63446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.90927345, sen-loss: 24.23744613, dom-loss: 77.67182720, train-acc: 0.92410714, val-acc: 0.88750000 val_loss: 0.29491022, dom-acc: 0.65339286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.60848814, sen-loss: 24.06041595, dom-loss: 77.54807198, train-acc: 0.92446429, val-acc: 0.89500000 val_loss: 0.29760483, dom-acc: 0.62116071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.10838395, sen-loss: 23.71055707, dom-loss: 77.39782685, train-acc: 0.92410714, val-acc: 0.89250000 val_loss: 0.30589327, dom-acc: 0.67500000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.67700273, sen-loss: 23.40986809, dom-loss: 77.26713467, train-acc: 0.92482143, val-acc: 0.88750000 val_loss: 0.29611146, dom-acc: 0.67696429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.18380684, sen-loss: 23.09699324, dom-loss: 77.08681333, train-acc: 0.92750000, val-acc: 0.89500000 val_loss: 0.29686376, dom-acc: 0.70196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.24457031, sen-loss: 23.15369342, dom-loss: 77.09087688, train-acc: 0.92839286, val-acc: 0.88500000 val_loss: 0.29648247, dom-acc: 0.70696429
---------------------------------------------------

Successfully load model from save path: ./work/models/books_electronics_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.29491022
Testing accuracy: 0.83883333
./work/attentions/books_electronics_train.txt
./work/pivots/books_electronics_pos.txt
./work/pivots/books_electronics_neg.txt
./work/attentions/books_electronics_test.txt
loading data...
source domain:  books target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 13856
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
5600 400 6000 15750 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.69050539, sen-loss: 77.00462729, dom-loss: 81.68587822, train-acc: 0.68089286, val-acc: 0.68250000 val_loss: 0.65841991, dom-acc: 0.81571429
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 145.37075281, sen-loss: 70.64262056, dom-loss: 74.72813296, train-acc: 0.75696429, val-acc: 0.78250000 val_loss: 0.59280372, dom-acc: 0.87901786
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 135.05635417, sen-loss: 61.69020867, dom-loss: 73.36614567, train-acc: 0.81589286, val-acc: 0.81250000 val_loss: 0.49987036, dom-acc: 0.86348214
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 124.44395900, sen-loss: 51.15902501, dom-loss: 73.28493381, train-acc: 0.85321429, val-acc: 0.84750000 val_loss: 0.40663862, dom-acc: 0.82428571
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.79341179, sen-loss: 41.87745841, dom-loss: 73.91595364, train-acc: 0.87232143, val-acc: 0.87000000 val_loss: 0.35788262, dom-acc: 0.77196429
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.68947804, sen-loss: 36.95219810, dom-loss: 74.73728007, train-acc: 0.87714286, val-acc: 0.86750000 val_loss: 0.34700531, dom-acc: 0.74285714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.03313595, sen-loss: 35.17256327, dom-loss: 75.86057276, train-acc: 0.88285714, val-acc: 0.88000000 val_loss: 0.34528798, dom-acc: 0.71348214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.81530839, sen-loss: 34.11760628, dom-loss: 76.69770277, train-acc: 0.88517857, val-acc: 0.87250000 val_loss: 0.33599809, dom-acc: 0.68875000
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.88623202, sen-loss: 33.49481125, dom-loss: 77.39142084, train-acc: 0.88250000, val-acc: 0.87500000 val_loss: 0.35156214, dom-acc: 0.67526786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.78037655, sen-loss: 32.68351007, dom-loss: 78.09686613, train-acc: 0.88821429, val-acc: 0.87750000 val_loss: 0.33307546, dom-acc: 0.65741071
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.04774958, sen-loss: 32.33759493, dom-loss: 78.71015501, train-acc: 0.89232143, val-acc: 0.88250000 val_loss: 0.32477653, dom-acc: 0.63348214
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.32537925, sen-loss: 31.46858658, dom-loss: 78.85679305, train-acc: 0.89392857, val-acc: 0.88250000 val_loss: 0.32208335, dom-acc: 0.62357143
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.20830107, sen-loss: 31.14598025, dom-loss: 79.06232059, train-acc: 0.89392857, val-acc: 0.88000000 val_loss: 0.32751817, dom-acc: 0.61714286
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 109.70000237, sen-loss: 30.57636395, dom-loss: 79.12363774, train-acc: 0.89785714, val-acc: 0.88250000 val_loss: 0.31921795, dom-acc: 0.60062500
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.15382862, sen-loss: 30.12671170, dom-loss: 79.02711666, train-acc: 0.89928571, val-acc: 0.88250000 val_loss: 0.31601152, dom-acc: 0.60616071
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.45286739, sen-loss: 29.70436269, dom-loss: 78.74850464, train-acc: 0.90017857, val-acc: 0.88000000 val_loss: 0.31558344, dom-acc: 0.62455357
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.05392754, sen-loss: 29.34654732, dom-loss: 78.70738024, train-acc: 0.90160714, val-acc: 0.88500000 val_loss: 0.31761813, dom-acc: 0.62294643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.36345279, sen-loss: 29.11601277, dom-loss: 78.24744004, train-acc: 0.90446429, val-acc: 0.88250000 val_loss: 0.31288475, dom-acc: 0.63276786
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.89235383, sen-loss: 28.64662286, dom-loss: 78.24573094, train-acc: 0.90571429, val-acc: 0.88250000 val_loss: 0.31234622, dom-acc: 0.62526786
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.41126680, sen-loss: 28.24627091, dom-loss: 78.16499597, train-acc: 0.90821429, val-acc: 0.88000000 val_loss: 0.31201801, dom-acc: 0.62446429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 105.87420923, sen-loss: 28.04742394, dom-loss: 77.82678556, train-acc: 0.90785714, val-acc: 0.88500000 val_loss: 0.30969235, dom-acc: 0.63839286
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 105.43706077, sen-loss: 27.80044083, dom-loss: 77.63662010, train-acc: 0.91035714, val-acc: 0.88500000 val_loss: 0.30904552, dom-acc: 0.64455357
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 105.13374811, sen-loss: 27.40794641, dom-loss: 77.72580189, train-acc: 0.91250000, val-acc: 0.89000000 val_loss: 0.30967355, dom-acc: 0.64169643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 104.85920531, sen-loss: 27.33928921, dom-loss: 77.51991642, train-acc: 0.91321429, val-acc: 0.88750000 val_loss: 0.30670241, dom-acc: 0.64294643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.16694337, sen-loss: 26.77823036, dom-loss: 77.38871306, train-acc: 0.91321429, val-acc: 0.88750000 val_loss: 0.30615529, dom-acc: 0.63785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.96330881, sen-loss: 26.60306406, dom-loss: 77.36024457, train-acc: 0.91375000, val-acc: 0.88750000 val_loss: 0.31139994, dom-acc: 0.64660714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 103.74441719, sen-loss: 26.36913791, dom-loss: 77.37527925, train-acc: 0.91464286, val-acc: 0.88250000 val_loss: 0.30434030, dom-acc: 0.64732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 103.56791151, sen-loss: 26.20393496, dom-loss: 77.36397666, train-acc: 0.91589286, val-acc: 0.89000000 val_loss: 0.30359858, dom-acc: 0.64285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 103.16050971, sen-loss: 25.83287998, dom-loss: 77.32762933, train-acc: 0.91678571, val-acc: 0.88500000 val_loss: 0.30285698, dom-acc: 0.64750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.93860555, sen-loss: 25.56092402, dom-loss: 77.37768167, train-acc: 0.91660714, val-acc: 0.88500000 val_loss: 0.30230078, dom-acc: 0.64000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 102.55581862, sen-loss: 25.34851913, dom-loss: 77.20729941, train-acc: 0.91571429, val-acc: 0.88500000 val_loss: 0.31157446, dom-acc: 0.65669643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.19853783, sen-loss: 24.92522731, dom-loss: 77.27331060, train-acc: 0.91875000, val-acc: 0.88750000 val_loss: 0.30175099, dom-acc: 0.64866071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.98715967, sen-loss: 24.70754294, dom-loss: 77.27961653, train-acc: 0.92035714, val-acc: 0.89500000 val_loss: 0.30168769, dom-acc: 0.65625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.82085717, sen-loss: 24.56917217, dom-loss: 77.25168461, train-acc: 0.92107143, val-acc: 0.89500000 val_loss: 0.30116045, dom-acc: 0.66750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.39261973, sen-loss: 24.26345223, dom-loss: 77.12916768, train-acc: 0.92321429, val-acc: 0.89000000 val_loss: 0.29908234, dom-acc: 0.66508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.34614819, sen-loss: 24.12205764, dom-loss: 77.22409046, train-acc: 0.92160714, val-acc: 0.89500000 val_loss: 0.30147412, dom-acc: 0.67008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.86096197, sen-loss: 23.77571375, dom-loss: 77.08524841, train-acc: 0.92303571, val-acc: 0.89000000 val_loss: 0.31101716, dom-acc: 0.67446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.46814078, sen-loss: 23.43399958, dom-loss: 77.03414112, train-acc: 0.92392857, val-acc: 0.89250000 val_loss: 0.30053443, dom-acc: 0.66366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.19804889, sen-loss: 23.11698074, dom-loss: 77.08106816, train-acc: 0.92589286, val-acc: 0.89500000 val_loss: 0.30123281, dom-acc: 0.67366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.37150753, sen-loss: 23.24210521, dom-loss: 77.12940252, train-acc: 0.92696429, val-acc: 0.89750000 val_loss: 0.30069113, dom-acc: 0.68169643
---------------------------------------------------

Successfully load model from save path: ./work/models/books_kitchen_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.29908234
Testing accuracy: 0.85183333
./work/attentions/books_kitchen_train.txt
./work/pivots/books_kitchen_pos.txt
./work/pivots/books_kitchen_neg.txt
./work/attentions/books_kitchen_test.txt
loading data...
source domain:  books target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 30180
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 15750 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.41588271, sen-loss: 77.00354797, dom-loss: 81.41233510, train-acc: 0.68035714, val-acc: 0.67250000 val_loss: 0.65829533, dom-acc: 0.78428571
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 146.47627056, sen-loss: 70.57519794, dom-loss: 75.90107268, train-acc: 0.75678571, val-acc: 0.77750000 val_loss: 0.59169340, dom-acc: 0.80705357
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 136.70477712, sen-loss: 61.57961196, dom-loss: 75.12516499, train-acc: 0.81321429, val-acc: 0.81250000 val_loss: 0.49872458, dom-acc: 0.76714286
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 126.11570680, sen-loss: 51.07031944, dom-loss: 75.04538751, train-acc: 0.85625000, val-acc: 0.85000000 val_loss: 0.40303540, dom-acc: 0.72008929
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 116.86411095, sen-loss: 41.74062265, dom-loss: 75.12348843, train-acc: 0.87017857, val-acc: 0.87750000 val_loss: 0.35256267, dom-acc: 0.72089286
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 112.13157469, sen-loss: 36.91053271, dom-loss: 75.22104222, train-acc: 0.87714286, val-acc: 0.87500000 val_loss: 0.34134945, dom-acc: 0.74053571
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.65330482, sen-loss: 35.20054185, dom-loss: 75.45276248, train-acc: 0.87946429, val-acc: 0.88000000 val_loss: 0.33839861, dom-acc: 0.73535714
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 109.98378795, sen-loss: 34.14718145, dom-loss: 75.83660638, train-acc: 0.88482143, val-acc: 0.88250000 val_loss: 0.32828021, dom-acc: 0.73491071
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.33655059, sen-loss: 33.50872205, dom-loss: 75.82782894, train-acc: 0.88035714, val-acc: 0.88000000 val_loss: 0.34345251, dom-acc: 0.72812500
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 108.91000718, sen-loss: 32.72306941, dom-loss: 76.18693805, train-acc: 0.88839286, val-acc: 0.88250000 val_loss: 0.32570738, dom-acc: 0.71830357
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.95877337, sen-loss: 32.38545664, dom-loss: 76.57331651, train-acc: 0.89321429, val-acc: 0.88750000 val_loss: 0.31685093, dom-acc: 0.70928571
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.41038394, sen-loss: 31.51754634, dom-loss: 76.89283776, train-acc: 0.89482143, val-acc: 0.88500000 val_loss: 0.31402993, dom-acc: 0.70116071
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.13083243, sen-loss: 31.21254964, dom-loss: 76.91828310, train-acc: 0.89357143, val-acc: 0.88500000 val_loss: 0.32031149, dom-acc: 0.69794643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.02400744, sen-loss: 30.63200185, dom-loss: 77.39200592, train-acc: 0.89785714, val-acc: 0.89250000 val_loss: 0.31112608, dom-acc: 0.67410714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 107.86677599, sen-loss: 30.19785148, dom-loss: 77.66892433, train-acc: 0.90000000, val-acc: 0.88750000 val_loss: 0.30795109, dom-acc: 0.67392857
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 107.41880018, sen-loss: 29.77870159, dom-loss: 77.64009839, train-acc: 0.90178571, val-acc: 0.89000000 val_loss: 0.30726644, dom-acc: 0.66848214
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.42995447, sen-loss: 29.41289708, dom-loss: 78.01705694, train-acc: 0.90125000, val-acc: 0.88750000 val_loss: 0.30973187, dom-acc: 0.65848214
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.28636503, sen-loss: 29.22850247, dom-loss: 78.05786246, train-acc: 0.90482143, val-acc: 0.89250000 val_loss: 0.30463761, dom-acc: 0.65678571
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.05966043, sen-loss: 28.73176780, dom-loss: 78.32789260, train-acc: 0.90589286, val-acc: 0.89000000 val_loss: 0.30440369, dom-acc: 0.64267857
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.78200942, sen-loss: 28.34239136, dom-loss: 78.43961740, train-acc: 0.90803571, val-acc: 0.88750000 val_loss: 0.30442324, dom-acc: 0.64187500
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 106.63933802, sen-loss: 28.15809716, dom-loss: 78.48124045, train-acc: 0.90803571, val-acc: 0.89000000 val_loss: 0.30149513, dom-acc: 0.63294643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 106.47662354, sen-loss: 27.89786002, dom-loss: 78.57876360, train-acc: 0.90964286, val-acc: 0.89250000 val_loss: 0.30080935, dom-acc: 0.64151786
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 106.20153600, sen-loss: 27.51497288, dom-loss: 78.68656290, train-acc: 0.91089286, val-acc: 0.89000000 val_loss: 0.30086476, dom-acc: 0.63419643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.08668977, sen-loss: 27.46264993, dom-loss: 78.62403977, train-acc: 0.91214286, val-acc: 0.89000000 val_loss: 0.29802623, dom-acc: 0.62857143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 105.56030518, sen-loss: 26.89766109, dom-loss: 78.66264379, train-acc: 0.91250000, val-acc: 0.89000000 val_loss: 0.29726815, dom-acc: 0.62330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 105.27049977, sen-loss: 26.72752924, dom-loss: 78.54297042, train-acc: 0.91285714, val-acc: 0.89250000 val_loss: 0.30313000, dom-acc: 0.62750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 105.11293375, sen-loss: 26.49859727, dom-loss: 78.61433667, train-acc: 0.91339286, val-acc: 0.88500000 val_loss: 0.29524276, dom-acc: 0.63482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 104.80359727, sen-loss: 26.32927043, dom-loss: 78.47432691, train-acc: 0.91607143, val-acc: 0.89250000 val_loss: 0.29437029, dom-acc: 0.62678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 104.34834975, sen-loss: 25.96207874, dom-loss: 78.38627118, train-acc: 0.91642857, val-acc: 0.88750000 val_loss: 0.29315436, dom-acc: 0.63821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 103.93527597, sen-loss: 25.68074057, dom-loss: 78.25453562, train-acc: 0.91607143, val-acc: 0.88750000 val_loss: 0.29236683, dom-acc: 0.63553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.48092574, sen-loss: 25.45889147, dom-loss: 78.02203476, train-acc: 0.91678571, val-acc: 0.89000000 val_loss: 0.30126652, dom-acc: 0.65089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.94511592, sen-loss: 25.05547534, dom-loss: 77.88964033, train-acc: 0.91875000, val-acc: 0.89000000 val_loss: 0.29146609, dom-acc: 0.63553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.84567100, sen-loss: 24.86780757, dom-loss: 77.97786337, train-acc: 0.92035714, val-acc: 0.89500000 val_loss: 0.29110301, dom-acc: 0.64535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.47355521, sen-loss: 24.70967356, dom-loss: 77.76388186, train-acc: 0.92053571, val-acc: 0.89750000 val_loss: 0.29042953, dom-acc: 0.65901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.85288125, sen-loss: 24.41785184, dom-loss: 77.43502933, train-acc: 0.92160714, val-acc: 0.89750000 val_loss: 0.28808859, dom-acc: 0.65732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.76705712, sen-loss: 24.23785720, dom-loss: 77.52919948, train-acc: 0.92303571, val-acc: 0.89750000 val_loss: 0.29001293, dom-acc: 0.64919643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.13388145, sen-loss: 23.90122320, dom-loss: 77.23265803, train-acc: 0.92375000, val-acc: 0.89250000 val_loss: 0.29941303, dom-acc: 0.67160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.67212415, sen-loss: 23.60864083, dom-loss: 77.06348342, train-acc: 0.92250000, val-acc: 0.89000000 val_loss: 0.28810072, dom-acc: 0.65910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.33248222, sen-loss: 23.27644093, dom-loss: 77.05604136, train-acc: 0.92750000, val-acc: 0.89750000 val_loss: 0.28918779, dom-acc: 0.66678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.38107276, sen-loss: 23.37454315, dom-loss: 77.00652963, train-acc: 0.92607143, val-acc: 0.90000000 val_loss: 0.28728732, dom-acc: 0.67330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.64069712, sen-loss: 22.77707857, dom-loss: 76.86361825, train-acc: 0.92946429, val-acc: 0.89500000 val_loss: 0.28963098, dom-acc: 0.67321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.11977798, sen-loss: 22.47670290, dom-loss: 76.64307511, train-acc: 0.92857143, val-acc: 0.90000000 val_loss: 0.28749824, dom-acc: 0.67589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 98.84855586, sen-loss: 22.18659345, dom-loss: 76.66196203, train-acc: 0.93160714, val-acc: 0.89750000 val_loss: 0.28910029, dom-acc: 0.68071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [44 ] loss: 98.59047657, sen-loss: 22.01197232, dom-loss: 76.57850403, train-acc: 0.93125000, val-acc: 0.89250000 val_loss: 0.29332498, dom-acc: 0.68428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [45 ] loss: 98.40216893, sen-loss: 21.87318528, dom-loss: 76.52898359, train-acc: 0.93214286, val-acc: 0.89000000 val_loss: 0.29477412, dom-acc: 0.68250000
---------------------------------------------------

Successfully load model from save path: ./work/models/books_video_PNet.ckpt
Best Epoch: [ 40] best val accuracy: 0.00000000 best val loss: 0.28728732
Testing accuracy: 0.87283333
./work/attentions/books_video_train.txt
./work/pivots/books_video_pos.txt
./work/pivots/books_video_neg.txt
./work/attentions/books_video_test.txt
loading data...
source domain:  dvd target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 9750
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
5600 400 6000 17843 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.99689209, sen-loss: 77.37509912, dom-loss: 82.62179267, train-acc: 0.69321429, val-acc: 0.70000000 val_loss: 0.66347396, dom-acc: 0.68062500
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 148.61344683, sen-loss: 71.72560787, dom-loss: 76.88783896, train-acc: 0.74589286, val-acc: 0.76000000 val_loss: 0.60386652, dom-acc: 0.75517857
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 139.71016943, sen-loss: 64.02324101, dom-loss: 75.68692881, train-acc: 0.79535714, val-acc: 0.79750000 val_loss: 0.51631141, dom-acc: 0.76276786
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 129.71547246, sen-loss: 54.67635223, dom-loss: 75.03912044, train-acc: 0.83625000, val-acc: 0.84750000 val_loss: 0.42529553, dom-acc: 0.75455357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 121.01265413, sen-loss: 46.06035060, dom-loss: 74.95230383, train-acc: 0.85660714, val-acc: 0.87750000 val_loss: 0.35951945, dom-acc: 0.75205357
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 114.26487941, sen-loss: 40.07118863, dom-loss: 74.19369030, train-acc: 0.86625000, val-acc: 0.89250000 val_loss: 0.32655713, dom-acc: 0.74741071
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.80611390, sen-loss: 37.52836190, dom-loss: 74.27775234, train-acc: 0.87392857, val-acc: 0.88750000 val_loss: 0.32088369, dom-acc: 0.75116071
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.22956496, sen-loss: 36.16848645, dom-loss: 74.06107920, train-acc: 0.87571429, val-acc: 0.89750000 val_loss: 0.30996349, dom-acc: 0.74580357
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.53906244, sen-loss: 35.31597677, dom-loss: 74.22308600, train-acc: 0.87696429, val-acc: 0.90000000 val_loss: 0.30557644, dom-acc: 0.74267857
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.41899633, sen-loss: 34.90422572, dom-loss: 74.51477033, train-acc: 0.88214286, val-acc: 0.90000000 val_loss: 0.30490980, dom-acc: 0.73651786
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.44637418, sen-loss: 34.13596642, dom-loss: 74.31040794, train-acc: 0.88285714, val-acc: 0.90250000 val_loss: 0.30055234, dom-acc: 0.73187500
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.65562093, sen-loss: 33.59201007, dom-loss: 75.06361097, train-acc: 0.88482143, val-acc: 0.90250000 val_loss: 0.29999563, dom-acc: 0.72535714
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.54458785, sen-loss: 33.30463059, dom-loss: 75.23995727, train-acc: 0.88642857, val-acc: 0.90500000 val_loss: 0.29571953, dom-acc: 0.71964286
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.33795464, sen-loss: 32.64996567, dom-loss: 75.68798888, train-acc: 0.88589286, val-acc: 0.90250000 val_loss: 0.30060869, dom-acc: 0.70973214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 108.29104668, sen-loss: 32.36388995, dom-loss: 75.92715675, train-acc: 0.88678571, val-acc: 0.90750000 val_loss: 0.30058134, dom-acc: 0.70250000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.02902657, sen-loss: 32.14476502, dom-loss: 75.88426095, train-acc: 0.89321429, val-acc: 0.90500000 val_loss: 0.29240960, dom-acc: 0.70098214
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.32437742, sen-loss: 31.87141940, dom-loss: 76.45295805, train-acc: 0.88696429, val-acc: 0.90500000 val_loss: 0.30204114, dom-acc: 0.68937500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 108.07615143, sen-loss: 31.26685515, dom-loss: 76.80929595, train-acc: 0.89553571, val-acc: 0.91250000 val_loss: 0.29211131, dom-acc: 0.69035714
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.96837085, sen-loss: 31.04592334, dom-loss: 76.92244750, train-acc: 0.89517857, val-acc: 0.91000000 val_loss: 0.29239684, dom-acc: 0.67776786
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 107.87415439, sen-loss: 30.78715287, dom-loss: 77.08700132, train-acc: 0.89642857, val-acc: 0.90000000 val_loss: 0.28840914, dom-acc: 0.67500000
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 107.90189463, sen-loss: 30.49158424, dom-loss: 77.41031051, train-acc: 0.89875000, val-acc: 0.91250000 val_loss: 0.28909472, dom-acc: 0.67080357
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 107.83426970, sen-loss: 30.06169803, dom-loss: 77.77257180, train-acc: 0.89464286, val-acc: 0.91000000 val_loss: 0.29527354, dom-acc: 0.66357143
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 107.55568784, sen-loss: 29.93615933, dom-loss: 77.61952853, train-acc: 0.89928571, val-acc: 0.91500000 val_loss: 0.29041383, dom-acc: 0.66026786
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 107.72774512, sen-loss: 29.57875714, dom-loss: 78.14898837, train-acc: 0.90053571, val-acc: 0.91500000 val_loss: 0.29042307, dom-acc: 0.65428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 107.23734266, sen-loss: 29.45999502, dom-loss: 77.77734715, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.29357547, dom-acc: 0.66357143
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_books_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28840914
Testing accuracy: 0.87833333
./work/attentions/dvd_books_train.txt
./work/pivots/dvd_books_pos.txt
./work/pivots/dvd_books_neg.txt
./work/attentions/dvd_books_test.txt
loading data...
source domain:  dvd target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 17009
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
5600 400 6000 17843 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 160.32706213, sen-loss: 77.39226466, dom-loss: 82.93479675, train-acc: 0.68285714, val-acc: 0.69250000 val_loss: 0.66499299, dom-acc: 0.77339286
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 147.45266497, sen-loss: 71.90185052, dom-loss: 75.55081457, train-acc: 0.73892857, val-acc: 0.75000000 val_loss: 0.60601962, dom-acc: 0.88553571
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 137.79412353, sen-loss: 64.22345287, dom-loss: 73.57067060, train-acc: 0.79464286, val-acc: 0.79750000 val_loss: 0.51702791, dom-acc: 0.87267857
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 127.70184517, sen-loss: 54.77326387, dom-loss: 72.92858124, train-acc: 0.83857143, val-acc: 0.86000000 val_loss: 0.42333713, dom-acc: 0.83205357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 119.18000877, sen-loss: 46.05015898, dom-loss: 73.12985021, train-acc: 0.85839286, val-acc: 0.88500000 val_loss: 0.35614207, dom-acc: 0.78955357
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 113.55800831, sen-loss: 39.97462673, dom-loss: 73.58338165, train-acc: 0.86553571, val-acc: 0.89000000 val_loss: 0.32446915, dom-acc: 0.78687500
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.93028545, sen-loss: 37.46817838, dom-loss: 74.46210700, train-acc: 0.87553571, val-acc: 0.89250000 val_loss: 0.31831306, dom-acc: 0.79526786
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 111.43902075, sen-loss: 36.10762534, dom-loss: 75.33139521, train-acc: 0.87839286, val-acc: 0.89750000 val_loss: 0.30839106, dom-acc: 0.75937500
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 111.56582350, sen-loss: 35.28951560, dom-loss: 76.27630782, train-acc: 0.87750000, val-acc: 0.89750000 val_loss: 0.30375358, dom-acc: 0.69651786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 112.09687495, sen-loss: 34.89685528, dom-loss: 77.20001954, train-acc: 0.88232143, val-acc: 0.89750000 val_loss: 0.30362654, dom-acc: 0.63267857
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 112.15991396, sen-loss: 34.12366846, dom-loss: 78.03624564, train-acc: 0.88267857, val-acc: 0.89750000 val_loss: 0.29868624, dom-acc: 0.59169643
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 112.49285036, sen-loss: 33.58209384, dom-loss: 78.91075706, train-acc: 0.88482143, val-acc: 0.90000000 val_loss: 0.29849789, dom-acc: 0.54017857
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 112.82296246, sen-loss: 33.30069706, dom-loss: 79.52226597, train-acc: 0.88767857, val-acc: 0.90250000 val_loss: 0.29393557, dom-acc: 0.51258929
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 112.49031430, sen-loss: 32.63585015, dom-loss: 79.85446352, train-acc: 0.88446429, val-acc: 0.90750000 val_loss: 0.29910696, dom-acc: 0.49973214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 112.34169024, sen-loss: 32.36586437, dom-loss: 79.97582597, train-acc: 0.88660714, val-acc: 0.90750000 val_loss: 0.29956841, dom-acc: 0.47223214
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 112.21460700, sen-loss: 32.12289532, dom-loss: 80.09171212, train-acc: 0.89160714, val-acc: 0.90500000 val_loss: 0.29140094, dom-acc: 0.49785714
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 111.87763602, sen-loss: 31.86023043, dom-loss: 80.01740533, train-acc: 0.88803571, val-acc: 0.90250000 val_loss: 0.30136380, dom-acc: 0.48607143
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 111.14988989, sen-loss: 31.27732043, dom-loss: 79.87256914, train-acc: 0.89482143, val-acc: 0.90750000 val_loss: 0.29103944, dom-acc: 0.47473214
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 110.60798603, sen-loss: 31.04226537, dom-loss: 79.56572098, train-acc: 0.89482143, val-acc: 0.91000000 val_loss: 0.29177520, dom-acc: 0.43750000
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 110.12930244, sen-loss: 30.78193161, dom-loss: 79.34737116, train-acc: 0.89642857, val-acc: 0.90250000 val_loss: 0.28745684, dom-acc: 0.50741071
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 109.58707851, sen-loss: 30.50376265, dom-loss: 79.08331621, train-acc: 0.89892857, val-acc: 0.91250000 val_loss: 0.28885576, dom-acc: 0.51348214
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 108.96559620, sen-loss: 30.06088756, dom-loss: 78.90470880, train-acc: 0.89678571, val-acc: 0.91000000 val_loss: 0.29426518, dom-acc: 0.51187500
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 108.45541584, sen-loss: 29.92418176, dom-loss: 78.53123355, train-acc: 0.89964286, val-acc: 0.91250000 val_loss: 0.29053947, dom-acc: 0.52446429
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 107.92479980, sen-loss: 29.56970212, dom-loss: 78.35509831, train-acc: 0.90035714, val-acc: 0.91250000 val_loss: 0.29057953, dom-acc: 0.49589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 107.66708124, sen-loss: 29.46128750, dom-loss: 78.20579368, train-acc: 0.90071429, val-acc: 0.90750000 val_loss: 0.29346636, dom-acc: 0.57750000
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_electronics_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28745684
Testing accuracy: 0.83933333
./work/attentions/dvd_electronics_train.txt
./work/pivots/dvd_electronics_pos.txt
./work/pivots/dvd_electronics_neg.txt
./work/attentions/dvd_electronics_test.txt
loading data...
source domain:  dvd target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 13856
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
5600 400 6000 17843 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.86606407, sen-loss: 77.32742560, dom-loss: 82.53863823, train-acc: 0.69178571, val-acc: 0.70000000 val_loss: 0.66315663, dom-acc: 0.76241071
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 147.28258002, sen-loss: 71.76410180, dom-loss: 75.51847792, train-acc: 0.73785714, val-acc: 0.75250000 val_loss: 0.60349172, dom-acc: 0.85937500
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 137.94242382, sen-loss: 64.03160164, dom-loss: 73.91082269, train-acc: 0.79750000, val-acc: 0.80750000 val_loss: 0.51389879, dom-acc: 0.84357143
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 127.90863919, sen-loss: 54.52076870, dom-loss: 73.38787019, train-acc: 0.83892857, val-acc: 0.86000000 val_loss: 0.42026654, dom-acc: 0.80044643
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 119.43185782, sen-loss: 45.80328968, dom-loss: 73.62856793, train-acc: 0.85964286, val-acc: 0.88500000 val_loss: 0.35424486, dom-acc: 0.76750000
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 114.06205076, sen-loss: 39.83128171, dom-loss: 74.23076928, train-acc: 0.86589286, val-acc: 0.89250000 val_loss: 0.32248530, dom-acc: 0.73875000
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 112.32060468, sen-loss: 37.31687099, dom-loss: 75.00373346, train-acc: 0.87553571, val-acc: 0.89500000 val_loss: 0.31703833, dom-acc: 0.73062500
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 111.47777134, sen-loss: 35.99350828, dom-loss: 75.48426318, train-acc: 0.87714286, val-acc: 0.90250000 val_loss: 0.30610752, dom-acc: 0.70107143
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 111.71675813, sen-loss: 35.17372847, dom-loss: 76.54302913, train-acc: 0.87625000, val-acc: 0.90000000 val_loss: 0.30168194, dom-acc: 0.67875000
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 112.19131351, sen-loss: 34.77272816, dom-loss: 77.41858536, train-acc: 0.88232143, val-acc: 0.90250000 val_loss: 0.30085984, dom-acc: 0.66437500
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.84534729, sen-loss: 34.02079420, dom-loss: 77.82455266, train-acc: 0.88321429, val-acc: 0.90250000 val_loss: 0.29648736, dom-acc: 0.63294643
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 112.35380071, sen-loss: 33.48877594, dom-loss: 78.86502510, train-acc: 0.88446429, val-acc: 0.90250000 val_loss: 0.29576758, dom-acc: 0.60625000
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 112.70154637, sen-loss: 33.21191986, dom-loss: 79.48962617, train-acc: 0.88517857, val-acc: 0.90250000 val_loss: 0.29137373, dom-acc: 0.57116071
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 112.20200157, sen-loss: 32.56909190, dom-loss: 79.63290972, train-acc: 0.88535714, val-acc: 0.91250000 val_loss: 0.29586297, dom-acc: 0.58276786
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 111.98211694, sen-loss: 32.29965721, dom-loss: 79.68245959, train-acc: 0.88750000, val-acc: 0.91000000 val_loss: 0.29728201, dom-acc: 0.57883929
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 111.59974575, sen-loss: 32.09164420, dom-loss: 79.50810194, train-acc: 0.89142857, val-acc: 0.90500000 val_loss: 0.28803325, dom-acc: 0.57044643
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 111.41992819, sen-loss: 31.82477881, dom-loss: 79.59514934, train-acc: 0.88767857, val-acc: 0.90250000 val_loss: 0.29758874, dom-acc: 0.58116071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 110.47504848, sen-loss: 31.23594905, dom-loss: 79.23909926, train-acc: 0.89464286, val-acc: 0.91000000 val_loss: 0.28734946, dom-acc: 0.59714286
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 109.72838587, sen-loss: 31.01046532, dom-loss: 78.71792018, train-acc: 0.89446429, val-acc: 0.90500000 val_loss: 0.28763899, dom-acc: 0.59366071
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 109.14863503, sen-loss: 30.75420080, dom-loss: 78.39443386, train-acc: 0.89625000, val-acc: 0.90250000 val_loss: 0.28400186, dom-acc: 0.60973214
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 108.44942367, sen-loss: 30.47707964, dom-loss: 77.97234404, train-acc: 0.89875000, val-acc: 0.90750000 val_loss: 0.28475934, dom-acc: 0.63696429
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 107.86082548, sen-loss: 30.05382019, dom-loss: 77.80700499, train-acc: 0.89535714, val-acc: 0.91000000 val_loss: 0.29038644, dom-acc: 0.66321429
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 107.37544405, sen-loss: 29.91250736, dom-loss: 77.46293706, train-acc: 0.90053571, val-acc: 0.91000000 val_loss: 0.28588212, dom-acc: 0.67178571
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.80234343, sen-loss: 29.57746129, dom-loss: 77.22488201, train-acc: 0.90107143, val-acc: 0.91000000 val_loss: 0.28608489, dom-acc: 0.68741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 106.41045284, sen-loss: 29.45762661, dom-loss: 76.95282644, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.28845307, dom-acc: 0.69089286
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_kitchen_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28400186
Testing accuracy: 0.84666667
./work/attentions/dvd_kitchen_train.txt
./work/pivots/dvd_kitchen_pos.txt
./work/pivots/dvd_kitchen_neg.txt
./work/attentions/dvd_kitchen_test.txt
loading data...
source domain:  dvd target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 30180
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 17843 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 160.13918304, sen-loss: 77.42947477, dom-loss: 82.70970815, train-acc: 0.68714286, val-acc: 0.68750000 val_loss: 0.66539770, dom-acc: 0.57848214
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 150.61024940, sen-loss: 71.93259305, dom-loss: 78.67765617, train-acc: 0.73821429, val-acc: 0.74750000 val_loss: 0.60662061, dom-acc: 0.59633929
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 142.76203656, sen-loss: 64.29842839, dom-loss: 78.46360826, train-acc: 0.79357143, val-acc: 0.80750000 val_loss: 0.51807821, dom-acc: 0.62089286
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 133.03457463, sen-loss: 54.91803637, dom-loss: 78.11653811, train-acc: 0.83428571, val-acc: 0.86000000 val_loss: 0.42581737, dom-acc: 0.63964286
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 124.42673349, sen-loss: 46.45633525, dom-loss: 77.97039741, train-acc: 0.85250000, val-acc: 0.87750000 val_loss: 0.36216861, dom-acc: 0.63928571
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 118.29116368, sen-loss: 40.39803363, dom-loss: 77.89312953, train-acc: 0.86375000, val-acc: 0.89500000 val_loss: 0.32829508, dom-acc: 0.63937500
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 115.06784809, sen-loss: 37.64765909, dom-loss: 77.42018861, train-acc: 0.87553571, val-acc: 0.89000000 val_loss: 0.32258353, dom-acc: 0.66410714
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 113.53068691, sen-loss: 36.27028717, dom-loss: 77.26039922, train-acc: 0.87446429, val-acc: 0.89250000 val_loss: 0.31092572, dom-acc: 0.65473214
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 112.69736397, sen-loss: 35.42192328, dom-loss: 77.27544135, train-acc: 0.87607143, val-acc: 0.89500000 val_loss: 0.30573502, dom-acc: 0.65062500
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 112.34320772, sen-loss: 35.00487636, dom-loss: 77.33833134, train-acc: 0.88089286, val-acc: 0.90000000 val_loss: 0.30593121, dom-acc: 0.66651786
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.00205725, sen-loss: 34.25832792, dom-loss: 76.74372905, train-acc: 0.88267857, val-acc: 0.90000000 val_loss: 0.30056998, dom-acc: 0.66116071
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.98106354, sen-loss: 33.69534870, dom-loss: 77.28571469, train-acc: 0.88517857, val-acc: 0.90000000 val_loss: 0.30022228, dom-acc: 0.65973214
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.51820177, sen-loss: 33.40878262, dom-loss: 77.10941911, train-acc: 0.88589286, val-acc: 0.90000000 val_loss: 0.29556441, dom-acc: 0.65642857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 109.92698884, sen-loss: 32.74847388, dom-loss: 77.17851454, train-acc: 0.88642857, val-acc: 0.90500000 val_loss: 0.30027500, dom-acc: 0.67285714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.57161850, sen-loss: 32.48167235, dom-loss: 77.08994567, train-acc: 0.88696429, val-acc: 0.90500000 val_loss: 0.30140901, dom-acc: 0.67339286
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.67242712, sen-loss: 32.25022484, dom-loss: 76.42220289, train-acc: 0.88946429, val-acc: 0.90250000 val_loss: 0.29234356, dom-acc: 0.66732143
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 109.11967826, sen-loss: 31.97710250, dom-loss: 77.14257568, train-acc: 0.88696429, val-acc: 0.89750000 val_loss: 0.30234498, dom-acc: 0.67642857
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 108.17715549, sen-loss: 31.40010867, dom-loss: 76.77704638, train-acc: 0.89464286, val-acc: 0.91250000 val_loss: 0.29179239, dom-acc: 0.67276786
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.97644192, sen-loss: 31.16738106, dom-loss: 76.80906129, train-acc: 0.89410714, val-acc: 0.91000000 val_loss: 0.29143047, dom-acc: 0.66758929
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 107.55223840, sen-loss: 30.91523977, dom-loss: 76.63699871, train-acc: 0.89517857, val-acc: 0.89750000 val_loss: 0.28778878, dom-acc: 0.66446429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 107.20507216, sen-loss: 30.62519488, dom-loss: 76.57987732, train-acc: 0.89714286, val-acc: 0.91250000 val_loss: 0.28873092, dom-acc: 0.67080357
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 107.32948411, sen-loss: 30.19960967, dom-loss: 77.12987393, train-acc: 0.89535714, val-acc: 0.90500000 val_loss: 0.29395613, dom-acc: 0.67241071
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 106.73609322, sen-loss: 30.06363274, dom-loss: 76.67246109, train-acc: 0.89964286, val-acc: 0.91250000 val_loss: 0.28923625, dom-acc: 0.67223214
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.48955482, sen-loss: 29.71742076, dom-loss: 76.77213389, train-acc: 0.90125000, val-acc: 0.91250000 val_loss: 0.28939843, dom-acc: 0.67008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 106.21703637, sen-loss: 29.60408280, dom-loss: 76.61295378, train-acc: 0.89910714, val-acc: 0.91000000 val_loss: 0.29254940, dom-acc: 0.67767857
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_video_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28778878
Testing accuracy: 0.88216667
./work/attentions/dvd_video_train.txt
./work/pivots/dvd_video_pos.txt
./work/pivots/dvd_video_neg.txt
./work/attentions/dvd_video_test.txt
loading data...
source domain:  electronics target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 9750
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
5600 400 6000 23009 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.18004596, sen-loss: 75.79676020, dom-loss: 79.38328511, train-acc: 0.77535714, val-acc: 0.79750000 val_loss: 0.63261575, dom-acc: 0.88955357
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 137.97321522, sen-loss: 65.65786821, dom-loss: 72.31534708, train-acc: 0.78821429, val-acc: 0.82750000 val_loss: 0.50984728, dom-acc: 0.83696429
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 123.05978668, sen-loss: 52.45669070, dom-loss: 70.60309613, train-acc: 0.79464286, val-acc: 0.81500000 val_loss: 0.41831124, dom-acc: 0.63544643
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.72616684, sen-loss: 46.91938126, dom-loss: 70.80678463, train-acc: 0.83357143, val-acc: 0.86000000 val_loss: 0.36781517, dom-acc: 0.60410714
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 114.31931466, sen-loss: 42.47365110, dom-loss: 71.84566355, train-acc: 0.85767857, val-acc: 0.88250000 val_loss: 0.32859981, dom-acc: 0.58223214
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 112.19323856, sen-loss: 38.90623017, dom-loss: 73.28700882, train-acc: 0.86053571, val-acc: 0.88750000 val_loss: 0.30872324, dom-acc: 0.57035714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.95840991, sen-loss: 36.41521908, dom-loss: 74.54319018, train-acc: 0.87678571, val-acc: 0.89500000 val_loss: 0.27815518, dom-acc: 0.54598214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.65136558, sen-loss: 34.76505512, dom-loss: 75.88631004, train-acc: 0.88392857, val-acc: 0.90500000 val_loss: 0.26421443, dom-acc: 0.52678571
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.79007107, sen-loss: 33.57912862, dom-loss: 77.21094233, train-acc: 0.88803571, val-acc: 0.90500000 val_loss: 0.25780931, dom-acc: 0.50151786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.91346246, sen-loss: 32.57175234, dom-loss: 78.34171051, train-acc: 0.89053571, val-acc: 0.91000000 val_loss: 0.25502169, dom-acc: 0.47178571
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.21824086, sen-loss: 32.08964963, dom-loss: 79.12859100, train-acc: 0.89410714, val-acc: 0.91000000 val_loss: 0.24645784, dom-acc: 0.44044643
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 111.02530885, sen-loss: 31.24034896, dom-loss: 79.78496027, train-acc: 0.89660714, val-acc: 0.90500000 val_loss: 0.23940079, dom-acc: 0.43205357
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.53752649, sen-loss: 30.40859752, dom-loss: 80.12892860, train-acc: 0.90107143, val-acc: 0.91000000 val_loss: 0.23808593, dom-acc: 0.40803571
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 110.36316389, sen-loss: 29.84096582, dom-loss: 80.52219844, train-acc: 0.90125000, val-acc: 0.91500000 val_loss: 0.23343979, dom-acc: 0.40232143
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.74378365, sen-loss: 29.32138978, dom-loss: 80.42239439, train-acc: 0.90375000, val-acc: 0.92250000 val_loss: 0.23152228, dom-acc: 0.40339286
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 109.08016360, sen-loss: 28.82800381, dom-loss: 80.25216001, train-acc: 0.90482143, val-acc: 0.92250000 val_loss: 0.22985190, dom-acc: 0.40553571
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.10192591, sen-loss: 28.35361578, dom-loss: 79.74830997, train-acc: 0.90678571, val-acc: 0.92000000 val_loss: 0.22883649, dom-acc: 0.41580357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.47801560, sen-loss: 28.03542131, dom-loss: 79.44259411, train-acc: 0.90857143, val-acc: 0.92250000 val_loss: 0.22895345, dom-acc: 0.43241071
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.46331114, sen-loss: 27.65509884, dom-loss: 78.80821228, train-acc: 0.91000000, val-acc: 0.92250000 val_loss: 0.22521958, dom-acc: 0.45642857
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.45996124, sen-loss: 27.25829239, dom-loss: 78.20166880, train-acc: 0.91196429, val-acc: 0.92000000 val_loss: 0.22475192, dom-acc: 0.46821429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.85455054, sen-loss: 26.96362188, dom-loss: 77.89092851, train-acc: 0.91500000, val-acc: 0.92250000 val_loss: 0.22329010, dom-acc: 0.48544643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.83037490, sen-loss: 26.36953295, dom-loss: 77.46084183, train-acc: 0.91250000, val-acc: 0.92750000 val_loss: 0.22507659, dom-acc: 0.50803571
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 103.06314170, sen-loss: 26.14822443, dom-loss: 76.91491729, train-acc: 0.91607143, val-acc: 0.92500000 val_loss: 0.22279513, dom-acc: 0.51660714
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.57370722, sen-loss: 25.82372753, dom-loss: 76.74997991, train-acc: 0.91982143, val-acc: 0.92250000 val_loss: 0.22161987, dom-acc: 0.52776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.16967565, sen-loss: 25.51309384, dom-loss: 76.65658140, train-acc: 0.91785714, val-acc: 0.91750000 val_loss: 0.22205757, dom-acc: 0.53473214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.59194094, sen-loss: 25.13893439, dom-loss: 76.45300710, train-acc: 0.92107143, val-acc: 0.92000000 val_loss: 0.22058308, dom-acc: 0.52937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.34468430, sen-loss: 24.86716235, dom-loss: 76.47752184, train-acc: 0.92142857, val-acc: 0.92250000 val_loss: 0.22102973, dom-acc: 0.52607143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.08143467, sen-loss: 24.57937486, dom-loss: 76.50205952, train-acc: 0.92250000, val-acc: 0.92500000 val_loss: 0.21974729, dom-acc: 0.51000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.10590744, sen-loss: 24.23967055, dom-loss: 76.86623681, train-acc: 0.92357143, val-acc: 0.92500000 val_loss: 0.22085968, dom-acc: 0.54330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.71968389, sen-loss: 24.01741611, dom-loss: 76.70226753, train-acc: 0.92517857, val-acc: 0.92000000 val_loss: 0.21885303, dom-acc: 0.50598214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.91393656, sen-loss: 23.82823453, dom-loss: 77.08570206, train-acc: 0.92553571, val-acc: 0.92500000 val_loss: 0.21870708, dom-acc: 0.50857143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.62685251, sen-loss: 23.48781280, dom-loss: 77.13903981, train-acc: 0.92642857, val-acc: 0.92250000 val_loss: 0.22004347, dom-acc: 0.48767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.87173998, sen-loss: 23.21166283, dom-loss: 77.66007757, train-acc: 0.92642857, val-acc: 0.92500000 val_loss: 0.21981247, dom-acc: 0.48437500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.78832352, sen-loss: 22.99481611, dom-loss: 77.79350770, train-acc: 0.92910714, val-acc: 0.92000000 val_loss: 0.21786730, dom-acc: 0.47035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.92921036, sen-loss: 22.72690079, dom-loss: 78.20230949, train-acc: 0.93107143, val-acc: 0.92250000 val_loss: 0.21786411, dom-acc: 0.47187500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.64810872, sen-loss: 22.31063171, dom-loss: 78.33747715, train-acc: 0.93107143, val-acc: 0.92250000 val_loss: 0.21710181, dom-acc: 0.46205357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.63969350, sen-loss: 22.12321567, dom-loss: 78.51647824, train-acc: 0.92892857, val-acc: 0.91750000 val_loss: 0.22193101, dom-acc: 0.43383929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.60406893, sen-loss: 21.94770481, dom-loss: 78.65636408, train-acc: 0.93285714, val-acc: 0.92250000 val_loss: 0.21694003, dom-acc: 0.44258929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.48304915, sen-loss: 21.70517769, dom-loss: 78.77787185, train-acc: 0.93142857, val-acc: 0.92250000 val_loss: 0.22053778, dom-acc: 0.41071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.32365561, sen-loss: 21.43019133, dom-loss: 78.89346421, train-acc: 0.93517857, val-acc: 0.92750000 val_loss: 0.21830738, dom-acc: 0.42589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.91080266, sen-loss: 21.17342466, dom-loss: 78.73737770, train-acc: 0.93625000, val-acc: 0.92750000 val_loss: 0.22018412, dom-acc: 0.40714286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.43093711, sen-loss: 20.80768849, dom-loss: 78.62324864, train-acc: 0.93696429, val-acc: 0.92500000 val_loss: 0.22026919, dom-acc: 0.39982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 99.27638179, sen-loss: 20.65295602, dom-loss: 78.62342578, train-acc: 0.93982143, val-acc: 0.92500000 val_loss: 0.21951121, dom-acc: 0.42776786
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_books_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.21694003
Testing accuracy: 0.83283333
./work/attentions/electronics_books_train.txt
./work/pivots/electronics_books_pos.txt
./work/pivots/electronics_books_neg.txt
./work/attentions/electronics_books_test.txt
loading data...
source domain:  electronics target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 11843
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
5600 400 6000 23009 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.71901965, sen-loss: 75.76668227, dom-loss: 78.95233780, train-acc: 0.77535714, val-acc: 0.79500000 val_loss: 0.63180882, dom-acc: 0.89473214
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 137.27644420, sen-loss: 65.43115905, dom-loss: 71.84528577, train-acc: 0.78785714, val-acc: 0.82000000 val_loss: 0.50755686, dom-acc: 0.82928571
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 122.42378765, sen-loss: 52.23720074, dom-loss: 70.18658698, train-acc: 0.79428571, val-acc: 0.81750000 val_loss: 0.41699407, dom-acc: 0.63544643
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.08852875, sen-loss: 46.80890587, dom-loss: 70.27962309, train-acc: 0.83250000, val-acc: 0.86250000 val_loss: 0.36699218, dom-acc: 0.61946429
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 113.52685034, sen-loss: 42.38050148, dom-loss: 71.14634907, train-acc: 0.85785714, val-acc: 0.88250000 val_loss: 0.32811290, dom-acc: 0.60187500
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 110.95939088, sen-loss: 38.78222108, dom-loss: 72.17717004, train-acc: 0.86017857, val-acc: 0.89000000 val_loss: 0.30749199, dom-acc: 0.58491071
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.08368987, sen-loss: 36.28541024, dom-loss: 73.79828000, train-acc: 0.87875000, val-acc: 0.89000000 val_loss: 0.27693596, dom-acc: 0.57098214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 109.59302104, sen-loss: 34.63227922, dom-loss: 74.96074224, train-acc: 0.88357143, val-acc: 0.89500000 val_loss: 0.26261058, dom-acc: 0.55026786
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.64746737, sen-loss: 33.45386711, dom-loss: 76.19360030, train-acc: 0.89035714, val-acc: 0.90250000 val_loss: 0.25724497, dom-acc: 0.52285714
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.88900369, sen-loss: 32.44999737, dom-loss: 77.43900639, train-acc: 0.89285714, val-acc: 0.91750000 val_loss: 0.25432703, dom-acc: 0.49116071
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 110.33816886, sen-loss: 31.99372019, dom-loss: 78.34444880, train-acc: 0.89678571, val-acc: 0.91000000 val_loss: 0.24501573, dom-acc: 0.46901786
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.12271816, sen-loss: 31.15546368, dom-loss: 78.96725440, train-acc: 0.89875000, val-acc: 0.90750000 val_loss: 0.23708250, dom-acc: 0.45866071
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.05886137, sen-loss: 30.30479486, dom-loss: 79.75406599, train-acc: 0.90339286, val-acc: 0.90750000 val_loss: 0.23614669, dom-acc: 0.44169643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 110.08391958, sen-loss: 29.75811186, dom-loss: 80.32580811, train-acc: 0.90464286, val-acc: 0.91250000 val_loss: 0.23119895, dom-acc: 0.42883929
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.45111442, sen-loss: 29.26741928, dom-loss: 80.18369520, train-acc: 0.90589286, val-acc: 0.91500000 val_loss: 0.22911786, dom-acc: 0.42303571
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.97663802, sen-loss: 28.77540129, dom-loss: 80.20123732, train-acc: 0.90678571, val-acc: 0.91000000 val_loss: 0.22699255, dom-acc: 0.42526786
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.12008464, sen-loss: 28.32259013, dom-loss: 79.79749465, train-acc: 0.90821429, val-acc: 0.92000000 val_loss: 0.22599006, dom-acc: 0.43312500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.46187234, sen-loss: 28.00461904, dom-loss: 79.45725310, train-acc: 0.91035714, val-acc: 0.92250000 val_loss: 0.22626929, dom-acc: 0.43794643
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.57513428, sen-loss: 27.65559101, dom-loss: 78.91954350, train-acc: 0.91089286, val-acc: 0.91750000 val_loss: 0.22164476, dom-acc: 0.46357143
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.58925837, sen-loss: 27.24110808, dom-loss: 78.34815031, train-acc: 0.91321429, val-acc: 0.91000000 val_loss: 0.22036736, dom-acc: 0.48678571
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.80899113, sen-loss: 26.99155623, dom-loss: 77.81743431, train-acc: 0.91500000, val-acc: 0.91750000 val_loss: 0.21880664, dom-acc: 0.49500000
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.77718520, sen-loss: 26.36371057, dom-loss: 77.41347456, train-acc: 0.91428571, val-acc: 0.92250000 val_loss: 0.22035165, dom-acc: 0.50321429
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 103.09926844, sen-loss: 26.14243343, dom-loss: 76.95683539, train-acc: 0.91642857, val-acc: 0.92500000 val_loss: 0.21741012, dom-acc: 0.51866071
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.33200967, sen-loss: 25.82035835, dom-loss: 76.51165146, train-acc: 0.91964286, val-acc: 0.92250000 val_loss: 0.21592326, dom-acc: 0.51794643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.99505216, sen-loss: 25.48379985, dom-loss: 76.51125246, train-acc: 0.91785714, val-acc: 0.90750000 val_loss: 0.21602295, dom-acc: 0.53651786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.37245047, sen-loss: 25.11359648, dom-loss: 76.25885415, train-acc: 0.92035714, val-acc: 0.92000000 val_loss: 0.21413708, dom-acc: 0.53348214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.05544609, sen-loss: 24.87460039, dom-loss: 76.18084562, train-acc: 0.92125000, val-acc: 0.92500000 val_loss: 0.21450031, dom-acc: 0.53178571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 100.92833066, sen-loss: 24.56693143, dom-loss: 76.36139941, train-acc: 0.92357143, val-acc: 0.92500000 val_loss: 0.21257994, dom-acc: 0.52633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.76716566, sen-loss: 24.23429245, dom-loss: 76.53287321, train-acc: 0.92214286, val-acc: 0.92250000 val_loss: 0.21329585, dom-acc: 0.53089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.40175003, sen-loss: 24.00000027, dom-loss: 76.40174949, train-acc: 0.92607143, val-acc: 0.91750000 val_loss: 0.21107221, dom-acc: 0.51607143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.67595291, sen-loss: 23.83312458, dom-loss: 76.84282857, train-acc: 0.92678571, val-acc: 0.92750000 val_loss: 0.21028034, dom-acc: 0.51205357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.50908649, sen-loss: 23.47752102, dom-loss: 77.03156531, train-acc: 0.92500000, val-acc: 0.92000000 val_loss: 0.21187405, dom-acc: 0.50178571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.60415095, sen-loss: 23.22125218, dom-loss: 77.38289887, train-acc: 0.92660714, val-acc: 0.92250000 val_loss: 0.21084975, dom-acc: 0.49562500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.61388266, sen-loss: 23.00827159, dom-loss: 77.60561126, train-acc: 0.93053571, val-acc: 0.92250000 val_loss: 0.20885220, dom-acc: 0.49035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.71903473, sen-loss: 22.72926118, dom-loss: 77.98977357, train-acc: 0.92910714, val-acc: 0.92000000 val_loss: 0.20807500, dom-acc: 0.47607143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.49755043, sen-loss: 22.34022521, dom-loss: 78.15732515, train-acc: 0.93178571, val-acc: 0.92500000 val_loss: 0.20718314, dom-acc: 0.46821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.52898461, sen-loss: 22.15145800, dom-loss: 78.37752664, train-acc: 0.92946429, val-acc: 0.92250000 val_loss: 0.21213196, dom-acc: 0.44741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.50273919, sen-loss: 21.96352613, dom-loss: 78.53921354, train-acc: 0.93357143, val-acc: 0.92000000 val_loss: 0.20643812, dom-acc: 0.44321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.21502674, sen-loss: 21.73656078, dom-loss: 78.47846597, train-acc: 0.93339286, val-acc: 0.92000000 val_loss: 0.21008158, dom-acc: 0.42776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.28135043, sen-loss: 21.46411874, dom-loss: 78.81723166, train-acc: 0.93678571, val-acc: 0.92500000 val_loss: 0.20696709, dom-acc: 0.44008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.80554307, sen-loss: 21.22650626, dom-loss: 78.57903677, train-acc: 0.93767857, val-acc: 0.92750000 val_loss: 0.20836233, dom-acc: 0.43089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.27762181, sen-loss: 20.84250595, dom-loss: 78.43511599, train-acc: 0.93821429, val-acc: 0.92250000 val_loss: 0.20865805, dom-acc: 0.43276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 99.16735262, sen-loss: 20.71443725, dom-loss: 78.45291489, train-acc: 0.93946429, val-acc: 0.92000000 val_loss: 0.20676561, dom-acc: 0.44491071
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_dvd_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.20643812
Testing accuracy: 0.83400000
./work/attentions/electronics_dvd_train.txt
./work/pivots/electronics_dvd_pos.txt
./work/pivots/electronics_dvd_neg.txt
./work/attentions/electronics_dvd_test.txt
loading data...
source domain:  electronics target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 13856
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
5600 400 6000 23009 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 156.98690164, sen-loss: 75.83608735, dom-loss: 81.15081435, train-acc: 0.77750000, val-acc: 0.78250000 val_loss: 0.63289028, dom-acc: 0.76464286
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 141.45005941, sen-loss: 65.60731730, dom-loss: 75.84274238, train-acc: 0.78625000, val-acc: 0.82000000 val_loss: 0.50878656, dom-acc: 0.78562500
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 127.53224170, sen-loss: 52.48996592, dom-loss: 75.04227626, train-acc: 0.79392857, val-acc: 0.82000000 val_loss: 0.41851306, dom-acc: 0.73125000
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 122.09240907, sen-loss: 47.22098419, dom-loss: 74.87142426, train-acc: 0.83017857, val-acc: 0.85000000 val_loss: 0.37024814, dom-acc: 0.75437500
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 117.74811852, sen-loss: 42.96372406, dom-loss: 74.78439522, train-acc: 0.85535714, val-acc: 0.88500000 val_loss: 0.33157519, dom-acc: 0.74803571
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 114.25887114, sen-loss: 39.36100368, dom-loss: 74.89786804, train-acc: 0.85750000, val-acc: 0.88750000 val_loss: 0.31003499, dom-acc: 0.74107143
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.70999503, sen-loss: 36.80153316, dom-loss: 74.90846217, train-acc: 0.87732143, val-acc: 0.89000000 val_loss: 0.27792618, dom-acc: 0.74026786
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.04677010, sen-loss: 35.05691729, dom-loss: 74.98985255, train-acc: 0.88303571, val-acc: 0.89750000 val_loss: 0.26242399, dom-acc: 0.73151786
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.17639977, sen-loss: 33.81528735, dom-loss: 75.36111265, train-acc: 0.88964286, val-acc: 0.91250000 val_loss: 0.25564608, dom-acc: 0.73151786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 108.25924450, sen-loss: 32.78365636, dom-loss: 75.47558767, train-acc: 0.89017857, val-acc: 0.92000000 val_loss: 0.25226980, dom-acc: 0.72767857
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.04613954, sen-loss: 32.31960439, dom-loss: 75.72653496, train-acc: 0.89553571, val-acc: 0.91750000 val_loss: 0.24209501, dom-acc: 0.72133929
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 107.30321735, sen-loss: 31.42747021, dom-loss: 75.87574780, train-acc: 0.89964286, val-acc: 0.91250000 val_loss: 0.23357700, dom-acc: 0.71366071
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 106.91315532, sen-loss: 30.60056877, dom-loss: 76.31258625, train-acc: 0.89982143, val-acc: 0.92000000 val_loss: 0.23249803, dom-acc: 0.71285714
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.57635438, sen-loss: 30.04809271, dom-loss: 76.52826178, train-acc: 0.90428571, val-acc: 0.92000000 val_loss: 0.22669947, dom-acc: 0.70910714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.04487628, sen-loss: 29.55033179, dom-loss: 76.49454498, train-acc: 0.90625000, val-acc: 0.92250000 val_loss: 0.22407211, dom-acc: 0.69767857
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.82725489, sen-loss: 29.04676809, dom-loss: 76.78048664, train-acc: 0.90767857, val-acc: 0.92500000 val_loss: 0.22181340, dom-acc: 0.69294643
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 105.69451070, sen-loss: 28.60148359, dom-loss: 77.09302682, train-acc: 0.90660714, val-acc: 0.93000000 val_loss: 0.22061582, dom-acc: 0.68178571
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 105.51020944, sen-loss: 28.26974665, dom-loss: 77.24046284, train-acc: 0.90750000, val-acc: 0.92750000 val_loss: 0.22061314, dom-acc: 0.68741071
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 105.19873422, sen-loss: 27.90008616, dom-loss: 77.29864824, train-acc: 0.91142857, val-acc: 0.92500000 val_loss: 0.21547033, dom-acc: 0.67937500
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.16818213, sen-loss: 27.49242316, dom-loss: 77.67575926, train-acc: 0.91178571, val-acc: 0.92000000 val_loss: 0.21390450, dom-acc: 0.66446429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.86847526, sen-loss: 27.23692381, dom-loss: 77.63155133, train-acc: 0.91482143, val-acc: 0.92750000 val_loss: 0.21219394, dom-acc: 0.66937500
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 104.45655352, sen-loss: 26.59279811, dom-loss: 77.86375523, train-acc: 0.91196429, val-acc: 0.93250000 val_loss: 0.21420610, dom-acc: 0.67598214
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 104.49485278, sen-loss: 26.37137391, dom-loss: 78.12347943, train-acc: 0.91464286, val-acc: 0.93000000 val_loss: 0.21143053, dom-acc: 0.66812500
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 104.10225594, sen-loss: 26.03662769, dom-loss: 78.06562823, train-acc: 0.91892857, val-acc: 0.93000000 val_loss: 0.20895706, dom-acc: 0.66178571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.66185713, sen-loss: 25.67685019, dom-loss: 77.98500675, train-acc: 0.91678571, val-acc: 0.92250000 val_loss: 0.20780937, dom-acc: 0.65276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.49271053, sen-loss: 25.31038255, dom-loss: 78.18232805, train-acc: 0.92107143, val-acc: 0.93000000 val_loss: 0.20700245, dom-acc: 0.64321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 103.11496305, sen-loss: 25.04042541, dom-loss: 78.07453793, train-acc: 0.92089286, val-acc: 0.92500000 val_loss: 0.20761935, dom-acc: 0.65633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.95080590, sen-loss: 24.73920107, dom-loss: 78.21160454, train-acc: 0.92339286, val-acc: 0.93000000 val_loss: 0.20519786, dom-acc: 0.64964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.28979832, sen-loss: 24.40136636, dom-loss: 77.88843197, train-acc: 0.92250000, val-acc: 0.92500000 val_loss: 0.20674345, dom-acc: 0.67258929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.31843746, sen-loss: 24.14584249, dom-loss: 78.17259455, train-acc: 0.92517857, val-acc: 0.93000000 val_loss: 0.20334601, dom-acc: 0.64732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.96503222, sen-loss: 23.96848965, dom-loss: 77.99654257, train-acc: 0.92589286, val-acc: 0.92750000 val_loss: 0.20243058, dom-acc: 0.66125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.53434741, sen-loss: 23.61055414, dom-loss: 77.92379332, train-acc: 0.92535714, val-acc: 0.92500000 val_loss: 0.20490600, dom-acc: 0.66678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.28227109, sen-loss: 23.34494817, dom-loss: 77.93732303, train-acc: 0.92696429, val-acc: 0.92500000 val_loss: 0.20367038, dom-acc: 0.66107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.11913824, sen-loss: 23.12722056, dom-loss: 77.99191779, train-acc: 0.92892857, val-acc: 0.93000000 val_loss: 0.20002978, dom-acc: 0.65071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.52706403, sen-loss: 22.83902735, dom-loss: 77.68803674, train-acc: 0.93053571, val-acc: 0.92750000 val_loss: 0.20038283, dom-acc: 0.65803571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.98787135, sen-loss: 22.44458527, dom-loss: 77.54328555, train-acc: 0.93107143, val-acc: 0.92750000 val_loss: 0.19892740, dom-acc: 0.66937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.76955843, sen-loss: 22.25380851, dom-loss: 77.51574969, train-acc: 0.93035714, val-acc: 0.92250000 val_loss: 0.20437098, dom-acc: 0.67821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.41171110, sen-loss: 22.08764463, dom-loss: 77.32406682, train-acc: 0.93392857, val-acc: 0.92750000 val_loss: 0.19721164, dom-acc: 0.67044643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.38261247, sen-loss: 21.84868769, dom-loss: 77.53392446, train-acc: 0.93339286, val-acc: 0.92750000 val_loss: 0.20154576, dom-acc: 0.67133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.59173477, sen-loss: 21.56486566, dom-loss: 77.02686870, train-acc: 0.93375000, val-acc: 0.93000000 val_loss: 0.19843800, dom-acc: 0.68321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 98.44038606, sen-loss: 21.32732799, dom-loss: 77.11305797, train-acc: 0.93517857, val-acc: 0.92750000 val_loss: 0.19965234, dom-acc: 0.67910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 98.07695884, sen-loss: 20.96377207, dom-loss: 77.11318702, train-acc: 0.93732143, val-acc: 0.93000000 val_loss: 0.19954690, dom-acc: 0.67767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 97.51332402, sen-loss: 20.79826088, dom-loss: 76.71506304, train-acc: 0.93857143, val-acc: 0.92750000 val_loss: 0.19764793, dom-acc: 0.67035714
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_kitchen_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.19721164
Testing accuracy: 0.90100000
./work/attentions/electronics_kitchen_train.txt
./work/pivots/electronics_kitchen_pos.txt
./work/pivots/electronics_kitchen_neg.txt
./work/attentions/electronics_kitchen_test.txt
loading data...
source domain:  electronics target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 30180
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 23009 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.78046095, sen-loss: 75.89951086, dom-loss: 78.88095003, train-acc: 0.77035714, val-acc: 0.80500000 val_loss: 0.63320881, dom-acc: 0.90937500
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 137.37747574, sen-loss: 65.74364293, dom-loss: 71.63383317, train-acc: 0.78589286, val-acc: 0.82250000 val_loss: 0.50902647, dom-acc: 0.86580357
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 122.78565890, sen-loss: 52.58729059, dom-loss: 70.19836837, train-acc: 0.79196429, val-acc: 0.80750000 val_loss: 0.41799611, dom-acc: 0.66553571
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.21740574, sen-loss: 47.20552823, dom-loss: 70.01187766, train-acc: 0.83089286, val-acc: 0.86000000 val_loss: 0.36856452, dom-acc: 0.62598214
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 114.07662570, sen-loss: 42.82481477, dom-loss: 71.25181079, train-acc: 0.85553571, val-acc: 0.88250000 val_loss: 0.32940039, dom-acc: 0.60732143
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.68028265, sen-loss: 39.15937516, dom-loss: 72.52090752, train-acc: 0.85696429, val-acc: 0.89000000 val_loss: 0.30776227, dom-acc: 0.58571429
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.80177999, sen-loss: 36.56058368, dom-loss: 74.24119657, train-acc: 0.87785714, val-acc: 0.89750000 val_loss: 0.27581435, dom-acc: 0.56544643
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.45577490, sen-loss: 34.84691358, dom-loss: 75.60886139, train-acc: 0.88357143, val-acc: 0.90750000 val_loss: 0.26066110, dom-acc: 0.54142857
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.64767408, sen-loss: 33.66003071, dom-loss: 76.98764366, train-acc: 0.89160714, val-acc: 0.91250000 val_loss: 0.25459126, dom-acc: 0.51169643
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.88414884, sen-loss: 32.61543934, dom-loss: 78.26870954, train-acc: 0.89285714, val-acc: 0.91750000 val_loss: 0.25076804, dom-acc: 0.48044643
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.39748091, sen-loss: 32.17304515, dom-loss: 79.22443599, train-acc: 0.89625000, val-acc: 0.91500000 val_loss: 0.24242902, dom-acc: 0.45312500
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 111.04058361, sen-loss: 31.31717578, dom-loss: 79.72340739, train-acc: 0.89892857, val-acc: 0.91250000 val_loss: 0.23417090, dom-acc: 0.43803571
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.73316151, sen-loss: 30.44454811, dom-loss: 80.28861368, train-acc: 0.90410714, val-acc: 0.92250000 val_loss: 0.23285605, dom-acc: 0.42669643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 110.43898690, sen-loss: 29.89480752, dom-loss: 80.54417944, train-acc: 0.90392857, val-acc: 0.92250000 val_loss: 0.22816327, dom-acc: 0.41776786
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.76784563, sen-loss: 29.40011220, dom-loss: 80.36773312, train-acc: 0.90625000, val-acc: 0.92750000 val_loss: 0.22618705, dom-acc: 0.42160714
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 109.09357184, sen-loss: 28.90086214, dom-loss: 80.19270974, train-acc: 0.90785714, val-acc: 0.92500000 val_loss: 0.22389486, dom-acc: 0.43642857
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.97023529, sen-loss: 28.44513378, dom-loss: 79.52510160, train-acc: 0.90892857, val-acc: 0.93500000 val_loss: 0.22314335, dom-acc: 0.44116071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.21699727, sen-loss: 28.12686387, dom-loss: 79.09013349, train-acc: 0.90946429, val-acc: 0.93250000 val_loss: 0.22287047, dom-acc: 0.46758929
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.23580670, sen-loss: 27.77542276, dom-loss: 78.46038359, train-acc: 0.91071429, val-acc: 0.93000000 val_loss: 0.21873190, dom-acc: 0.48901786
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.31292164, sen-loss: 27.35806292, dom-loss: 77.95485878, train-acc: 0.91250000, val-acc: 0.92000000 val_loss: 0.21744758, dom-acc: 0.51000000
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.59806615, sen-loss: 27.08043141, dom-loss: 77.51763433, train-acc: 0.91303571, val-acc: 0.92500000 val_loss: 0.21595554, dom-acc: 0.51696429
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.54134798, sen-loss: 26.47769752, dom-loss: 77.06365073, train-acc: 0.91553571, val-acc: 0.92500000 val_loss: 0.21784078, dom-acc: 0.52526786
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.99137181, sen-loss: 26.27876554, dom-loss: 76.71260649, train-acc: 0.91571429, val-acc: 0.93000000 val_loss: 0.21546948, dom-acc: 0.53410714
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.65893608, sen-loss: 25.93929802, dom-loss: 76.71963805, train-acc: 0.91714286, val-acc: 0.92500000 val_loss: 0.21325824, dom-acc: 0.53785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.25901330, sen-loss: 25.59021068, dom-loss: 76.66880274, train-acc: 0.91750000, val-acc: 0.91750000 val_loss: 0.21275254, dom-acc: 0.53973214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.65567130, sen-loss: 25.21074432, dom-loss: 76.44492692, train-acc: 0.92089286, val-acc: 0.92250000 val_loss: 0.21164462, dom-acc: 0.52785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.72251391, sen-loss: 24.96056247, dom-loss: 76.76195145, train-acc: 0.92125000, val-acc: 0.92500000 val_loss: 0.21242788, dom-acc: 0.52517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.62611043, sen-loss: 24.65170366, dom-loss: 76.97440684, train-acc: 0.92339286, val-acc: 0.92500000 val_loss: 0.21026605, dom-acc: 0.51035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.56652939, sen-loss: 24.30927467, dom-loss: 77.25725520, train-acc: 0.92178571, val-acc: 0.91750000 val_loss: 0.21147281, dom-acc: 0.52160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.41447532, sen-loss: 24.08050147, dom-loss: 77.33397365, train-acc: 0.92517857, val-acc: 0.92250000 val_loss: 0.20881589, dom-acc: 0.49732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.71180624, sen-loss: 23.92540105, dom-loss: 77.78640527, train-acc: 0.92660714, val-acc: 0.92500000 val_loss: 0.20831305, dom-acc: 0.48589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.68951666, sen-loss: 23.54999961, dom-loss: 78.13951719, train-acc: 0.92535714, val-acc: 0.91750000 val_loss: 0.21043666, dom-acc: 0.47535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.72893918, sen-loss: 23.29833338, dom-loss: 78.43060577, train-acc: 0.92589286, val-acc: 0.91750000 val_loss: 0.20963441, dom-acc: 0.45883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.49664086, sen-loss: 23.07039205, dom-loss: 78.42624873, train-acc: 0.92821429, val-acc: 0.91750000 val_loss: 0.20640601, dom-acc: 0.43812500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.69384974, sen-loss: 22.79699185, dom-loss: 78.89685822, train-acc: 0.92803571, val-acc: 0.92250000 val_loss: 0.20733789, dom-acc: 0.43446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.35969597, sen-loss: 22.40063486, dom-loss: 78.95906109, train-acc: 0.92964286, val-acc: 0.92500000 val_loss: 0.20574872, dom-acc: 0.43267857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.20584363, sen-loss: 22.19700859, dom-loss: 79.00883472, train-acc: 0.93071429, val-acc: 0.91500000 val_loss: 0.21130866, dom-acc: 0.41928571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.98832172, sen-loss: 22.02211849, dom-loss: 78.96620333, train-acc: 0.93232143, val-acc: 0.92250000 val_loss: 0.20443183, dom-acc: 0.44392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.54875797, sen-loss: 21.79099391, dom-loss: 78.75776434, train-acc: 0.93250000, val-acc: 0.91750000 val_loss: 0.20947814, dom-acc: 0.42053571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.14227563, sen-loss: 21.51591323, dom-loss: 78.62636280, train-acc: 0.93464286, val-acc: 0.92250000 val_loss: 0.20574403, dom-acc: 0.44482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.53096634, sen-loss: 21.24326336, dom-loss: 78.28770322, train-acc: 0.93482143, val-acc: 0.92250000 val_loss: 0.20792434, dom-acc: 0.43776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 98.94090575, sen-loss: 20.88686125, dom-loss: 78.05404472, train-acc: 0.93625000, val-acc: 0.92000000 val_loss: 0.20760170, dom-acc: 0.45508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 98.47003943, sen-loss: 20.75033655, dom-loss: 77.71970320, train-acc: 0.93767857, val-acc: 0.92250000 val_loss: 0.20577623, dom-acc: 0.46598214
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_video_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.20443183
Testing accuracy: 0.83516667
./work/attentions/electronics_video_train.txt
./work/pivots/electronics_video_pos.txt
./work/pivots/electronics_video_neg.txt
./work/attentions/electronics_video_test.txt
loading data...
source domain:  kitchen target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 9750
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
5600 400 6000 19856 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.51494825, sen-loss: 75.15250850, dom-loss: 80.36243939, train-acc: 0.77910714, val-acc: 0.78500000 val_loss: 0.62645739, dom-acc: 0.86732143
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 136.94068933, sen-loss: 63.84493077, dom-loss: 73.09575814, train-acc: 0.80803571, val-acc: 0.83000000 val_loss: 0.49128160, dom-acc: 0.77526786
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 120.08610415, sen-loss: 49.15911666, dom-loss: 70.92698759, train-acc: 0.83607143, val-acc: 0.84000000 val_loss: 0.39045683, dom-acc: 0.60642857
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 113.49527121, sen-loss: 42.15067600, dom-loss: 71.34459502, train-acc: 0.85750000, val-acc: 0.85750000 val_loss: 0.35025516, dom-acc: 0.57955357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 109.95169067, sen-loss: 37.55634572, dom-loss: 72.39534467, train-acc: 0.87821429, val-acc: 0.88500000 val_loss: 0.32803184, dom-acc: 0.56571429
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 108.09507954, sen-loss: 34.10333219, dom-loss: 73.99174714, train-acc: 0.88142857, val-acc: 0.88500000 val_loss: 0.30126566, dom-acc: 0.56196429
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 106.77723610, sen-loss: 31.81480472, dom-loss: 74.96243131, train-acc: 0.89339286, val-acc: 0.89750000 val_loss: 0.29402831, dom-acc: 0.53910714
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.48939067, sen-loss: 30.24845243, dom-loss: 76.24093831, train-acc: 0.90196429, val-acc: 0.90500000 val_loss: 0.29074383, dom-acc: 0.51660714
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 106.78166753, sen-loss: 29.19168410, dom-loss: 77.58998328, train-acc: 0.90464286, val-acc: 0.90250000 val_loss: 0.29028073, dom-acc: 0.49366071
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 107.07795280, sen-loss: 28.49501666, dom-loss: 78.58293700, train-acc: 0.90642857, val-acc: 0.90500000 val_loss: 0.28843969, dom-acc: 0.46598214
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 107.34832090, sen-loss: 27.91233297, dom-loss: 79.43598813, train-acc: 0.90910714, val-acc: 0.91000000 val_loss: 0.28552884, dom-acc: 0.44214286
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 107.47801703, sen-loss: 27.41222813, dom-loss: 80.06578869, train-acc: 0.91160714, val-acc: 0.91000000 val_loss: 0.28689808, dom-acc: 0.42151786
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 106.98382819, sen-loss: 26.79815579, dom-loss: 80.18567246, train-acc: 0.91017857, val-acc: 0.90250000 val_loss: 0.30276832, dom-acc: 0.39517857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.58249420, sen-loss: 26.35865549, dom-loss: 80.22383827, train-acc: 0.91375000, val-acc: 0.92000000 val_loss: 0.27860034, dom-acc: 0.40982143
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.02984172, sen-loss: 25.87373154, dom-loss: 80.15611017, train-acc: 0.91625000, val-acc: 0.91750000 val_loss: 0.28159440, dom-acc: 0.40875000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.31053811, sen-loss: 25.65058371, dom-loss: 79.65995413, train-acc: 0.91785714, val-acc: 0.91750000 val_loss: 0.27949187, dom-acc: 0.42125000
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 104.23161989, sen-loss: 25.08021401, dom-loss: 79.15140563, train-acc: 0.91928571, val-acc: 0.92000000 val_loss: 0.27984226, dom-acc: 0.43419643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 103.51132923, sen-loss: 24.90418603, dom-loss: 78.60714340, train-acc: 0.91821429, val-acc: 0.92500000 val_loss: 0.27238974, dom-acc: 0.45803571
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 102.69582516, sen-loss: 24.47161157, dom-loss: 78.22421330, train-acc: 0.91910714, val-acc: 0.92500000 val_loss: 0.27178925, dom-acc: 0.49866071
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.94411784, sen-loss: 24.20710748, dom-loss: 77.73701024, train-acc: 0.92232143, val-acc: 0.92000000 val_loss: 0.27491775, dom-acc: 0.47294643
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 101.23475128, sen-loss: 23.87201747, dom-loss: 77.36273402, train-acc: 0.92339286, val-acc: 0.92000000 val_loss: 0.27888730, dom-acc: 0.49294643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 100.68999499, sen-loss: 23.58615896, dom-loss: 77.10383588, train-acc: 0.92375000, val-acc: 0.92250000 val_loss: 0.28275162, dom-acc: 0.51705357
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 100.28579360, sen-loss: 23.35700670, dom-loss: 76.92878681, train-acc: 0.92446429, val-acc: 0.92250000 val_loss: 0.28065827, dom-acc: 0.50651786
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 100.21396178, sen-loss: 23.18257152, dom-loss: 77.03139019, train-acc: 0.92767857, val-acc: 0.92250000 val_loss: 0.27648944, dom-acc: 0.51330357
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_books_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27178925
Testing accuracy: 0.83983333
./work/attentions/kitchen_books_train.txt
./work/pivots/kitchen_books_pos.txt
./work/pivots/kitchen_books_neg.txt
./work/attentions/kitchen_books_test.txt
loading data...
source domain:  kitchen target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 11843
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
5600 400 6000 19856 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.08540976, sen-loss: 75.12500679, dom-loss: 79.96040356, train-acc: 0.77571429, val-acc: 0.78500000 val_loss: 0.62536871, dom-acc: 0.86303571
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 136.92896354, sen-loss: 63.85886377, dom-loss: 73.07009947, train-acc: 0.81160714, val-acc: 0.83250000 val_loss: 0.49296334, dom-acc: 0.79464286
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 120.50303298, sen-loss: 49.27848664, dom-loss: 71.22454602, train-acc: 0.83678571, val-acc: 0.84500000 val_loss: 0.38998133, dom-acc: 0.61187500
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 113.82846916, sen-loss: 42.05717133, dom-loss: 71.77129805, train-acc: 0.85678571, val-acc: 0.86750000 val_loss: 0.35023537, dom-acc: 0.58562500
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 110.00240731, sen-loss: 37.43284069, dom-loss: 72.56956697, train-acc: 0.87839286, val-acc: 0.88750000 val_loss: 0.32828715, dom-acc: 0.56544643
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 107.99913514, sen-loss: 34.04918793, dom-loss: 73.94994724, train-acc: 0.87964286, val-acc: 0.89250000 val_loss: 0.30201972, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 106.83913612, sen-loss: 31.84869336, dom-loss: 74.99044305, train-acc: 0.89321429, val-acc: 0.90500000 val_loss: 0.29464868, dom-acc: 0.54133929
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.18265581, sen-loss: 30.24658141, dom-loss: 75.93607491, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.29026309, dom-acc: 0.51553571
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 106.34411097, sen-loss: 29.20341349, dom-loss: 77.14069724, train-acc: 0.90339286, val-acc: 0.90750000 val_loss: 0.28873965, dom-acc: 0.49616071
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 106.47708774, sen-loss: 28.50928606, dom-loss: 77.96780163, train-acc: 0.90642857, val-acc: 0.90750000 val_loss: 0.28602624, dom-acc: 0.47187500
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 106.75378907, sen-loss: 27.89547157, dom-loss: 78.85831785, train-acc: 0.90892857, val-acc: 0.91000000 val_loss: 0.28400525, dom-acc: 0.46133929
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 106.73039198, sen-loss: 27.40119276, dom-loss: 79.32919902, train-acc: 0.91000000, val-acc: 0.91000000 val_loss: 0.28512433, dom-acc: 0.43508929
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 106.48884737, sen-loss: 26.77750579, dom-loss: 79.71134156, train-acc: 0.90803571, val-acc: 0.91250000 val_loss: 0.29950449, dom-acc: 0.42107143
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.13413465, sen-loss: 26.33830680, dom-loss: 79.79582757, train-acc: 0.91464286, val-acc: 0.91750000 val_loss: 0.27552858, dom-acc: 0.43732143
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 105.64809841, sen-loss: 25.87724179, dom-loss: 79.77085692, train-acc: 0.91767857, val-acc: 0.91750000 val_loss: 0.27989191, dom-acc: 0.43544643
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.09130156, sen-loss: 25.65032205, dom-loss: 79.44097972, train-acc: 0.91964286, val-acc: 0.91750000 val_loss: 0.27689913, dom-acc: 0.43892857
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 104.14215010, sen-loss: 25.06090834, dom-loss: 79.08124197, train-acc: 0.92089286, val-acc: 0.91750000 val_loss: 0.27799723, dom-acc: 0.44705357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 103.36286420, sen-loss: 24.89651918, dom-loss: 78.46634477, train-acc: 0.91910714, val-acc: 0.92250000 val_loss: 0.26988518, dom-acc: 0.46250000
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 102.77476096, sen-loss: 24.46052697, dom-loss: 78.31423390, train-acc: 0.92178571, val-acc: 0.92500000 val_loss: 0.26931757, dom-acc: 0.48544643
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.83142060, sen-loss: 24.18970457, dom-loss: 77.64171594, train-acc: 0.92357143, val-acc: 0.92250000 val_loss: 0.27306572, dom-acc: 0.48303571
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 100.94700432, sen-loss: 23.84145713, dom-loss: 77.10554677, train-acc: 0.92571429, val-acc: 0.91750000 val_loss: 0.27725145, dom-acc: 0.49116071
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 100.37021601, sen-loss: 23.56832097, dom-loss: 76.80189514, train-acc: 0.92464286, val-acc: 0.92000000 val_loss: 0.28023449, dom-acc: 0.50428571
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 99.84220815, sen-loss: 23.32482804, dom-loss: 76.51737994, train-acc: 0.92464286, val-acc: 0.92000000 val_loss: 0.27946845, dom-acc: 0.50991071
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 99.41949266, sen-loss: 23.15388303, dom-loss: 76.26560962, train-acc: 0.92946429, val-acc: 0.92500000 val_loss: 0.27487400, dom-acc: 0.50991071
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_dvd_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.26931757
Testing accuracy: 0.83566667
./work/attentions/kitchen_dvd_train.txt
./work/pivots/kitchen_dvd_pos.txt
./work/pivots/kitchen_dvd_neg.txt
./work/attentions/kitchen_dvd_test.txt
loading data...
source domain:  kitchen target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 17009
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
5600 400 6000 19856 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.88033688, sen-loss: 75.20185870, dom-loss: 82.67847794, train-acc: 0.77803571, val-acc: 0.80250000 val_loss: 0.62705737, dom-acc: 0.65866071
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 141.13442349, sen-loss: 63.97707936, dom-loss: 77.15734392, train-acc: 0.80839286, val-acc: 0.83000000 val_loss: 0.49206865, dom-acc: 0.65553571
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 125.32832426, sen-loss: 49.26758987, dom-loss: 76.06073451, train-acc: 0.83375000, val-acc: 0.84000000 val_loss: 0.39072287, dom-acc: 0.55892857
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.95116639, sen-loss: 42.29875866, dom-loss: 75.65240753, train-acc: 0.85553571, val-acc: 0.85750000 val_loss: 0.35004377, dom-acc: 0.56303571
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 113.28917819, sen-loss: 37.69239986, dom-loss: 75.59677833, train-acc: 0.87767857, val-acc: 0.88000000 val_loss: 0.32722652, dom-acc: 0.57883929
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 109.87466115, sen-loss: 34.20998730, dom-loss: 75.66467404, train-acc: 0.88089286, val-acc: 0.87750000 val_loss: 0.30128944, dom-acc: 0.61973214
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 107.59164178, sen-loss: 31.87446657, dom-loss: 75.71717530, train-acc: 0.89571429, val-acc: 0.90500000 val_loss: 0.29422307, dom-acc: 0.62348214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.05299938, sen-loss: 30.26978701, dom-loss: 75.78321218, train-acc: 0.90071429, val-acc: 0.91000000 val_loss: 0.28949210, dom-acc: 0.62125000
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 105.04481733, sen-loss: 29.19716509, dom-loss: 75.84765232, train-acc: 0.90464286, val-acc: 0.90500000 val_loss: 0.28823394, dom-acc: 0.64383929
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 104.47095138, sen-loss: 28.52260096, dom-loss: 75.94835043, train-acc: 0.90714286, val-acc: 0.90250000 val_loss: 0.28650588, dom-acc: 0.60964286
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 103.98468864, sen-loss: 27.91793291, dom-loss: 76.06675547, train-acc: 0.90982143, val-acc: 0.91250000 val_loss: 0.28439763, dom-acc: 0.65160714
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 103.66175264, sen-loss: 27.37511375, dom-loss: 76.28663886, train-acc: 0.91196429, val-acc: 0.90500000 val_loss: 0.28703809, dom-acc: 0.63187500
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 103.11577338, sen-loss: 26.76047058, dom-loss: 76.35530233, train-acc: 0.90982143, val-acc: 0.90750000 val_loss: 0.30194524, dom-acc: 0.62767857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 102.89692855, sen-loss: 26.32543730, dom-loss: 76.57149166, train-acc: 0.91642857, val-acc: 0.92000000 val_loss: 0.27762946, dom-acc: 0.61437500
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 102.56840241, sen-loss: 25.81134147, dom-loss: 76.75706112, train-acc: 0.91803571, val-acc: 0.91250000 val_loss: 0.28185722, dom-acc: 0.59750000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 102.46885401, sen-loss: 25.58049478, dom-loss: 76.88835937, train-acc: 0.92035714, val-acc: 0.91750000 val_loss: 0.27964854, dom-acc: 0.61446429
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 102.06082577, sen-loss: 25.01213303, dom-loss: 77.04869264, train-acc: 0.91946429, val-acc: 0.91750000 val_loss: 0.27948225, dom-acc: 0.59357143
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 101.89410079, sen-loss: 24.81629702, dom-loss: 77.07780379, train-acc: 0.92035714, val-acc: 0.92500000 val_loss: 0.27256632, dom-acc: 0.54732143
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 101.77399141, sen-loss: 24.37935568, dom-loss: 77.39463603, train-acc: 0.92285714, val-acc: 0.92250000 val_loss: 0.27264518, dom-acc: 0.57562500
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.54502320, sen-loss: 24.08574776, dom-loss: 77.45927548, train-acc: 0.92482143, val-acc: 0.92000000 val_loss: 0.27495152, dom-acc: 0.56928571
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 101.38139713, sen-loss: 23.75500493, dom-loss: 77.62639219, train-acc: 0.92428571, val-acc: 0.91500000 val_loss: 0.27874729, dom-acc: 0.56169643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 101.21665895, sen-loss: 23.44927998, dom-loss: 77.76737911, train-acc: 0.92392857, val-acc: 0.92500000 val_loss: 0.28406948, dom-acc: 0.58232143
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 100.93039566, sen-loss: 23.22844084, dom-loss: 77.70195448, train-acc: 0.92607143, val-acc: 0.92750000 val_loss: 0.28178748, dom-acc: 0.54625000
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_electronics_PNet.ckpt
Best Epoch: [ 18] best val accuracy: 0.00000000 best val loss: 0.27256632
Testing accuracy: 0.88066667
./work/attentions/kitchen_electronics_train.txt
./work/pivots/kitchen_electronics_pos.txt
./work/pivots/kitchen_electronics_neg.txt
./work/attentions/kitchen_electronics_test.txt
loading data...
source domain:  kitchen target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 30180
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 19856 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.71090448, sen-loss: 75.06412411, dom-loss: 79.64678079, train-acc: 0.77964286, val-acc: 0.78500000 val_loss: 0.62459260, dom-acc: 0.89303571
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 135.83655608, sen-loss: 63.65610197, dom-loss: 72.18045378, train-acc: 0.81089286, val-acc: 0.82500000 val_loss: 0.48925287, dom-acc: 0.80214286
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 119.55329686, sen-loss: 49.07959330, dom-loss: 70.47370362, train-acc: 0.83517857, val-acc: 0.84500000 val_loss: 0.38911486, dom-acc: 0.62633929
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 112.82857871, sen-loss: 42.05905144, dom-loss: 70.76952720, train-acc: 0.85642857, val-acc: 0.86500000 val_loss: 0.34987769, dom-acc: 0.59169643
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 109.46369225, sen-loss: 37.44550900, dom-loss: 72.01818323, train-acc: 0.87910714, val-acc: 0.89000000 val_loss: 0.32809117, dom-acc: 0.57633929
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 107.66803014, sen-loss: 34.00184345, dom-loss: 73.66618663, train-acc: 0.88071429, val-acc: 0.88500000 val_loss: 0.30311593, dom-acc: 0.56580357
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 106.80321652, sen-loss: 31.81178759, dom-loss: 74.99142897, train-acc: 0.89553571, val-acc: 0.90250000 val_loss: 0.29642475, dom-acc: 0.54232143
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.48718303, sen-loss: 30.20102219, dom-loss: 76.28616130, train-acc: 0.90017857, val-acc: 0.90500000 val_loss: 0.29172474, dom-acc: 0.51232143
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 106.85717583, sen-loss: 29.15395240, dom-loss: 77.70322371, train-acc: 0.90500000, val-acc: 0.89500000 val_loss: 0.29062203, dom-acc: 0.48785714
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 107.25501311, sen-loss: 28.45459557, dom-loss: 78.80041826, train-acc: 0.90732143, val-acc: 0.90000000 val_loss: 0.28820682, dom-acc: 0.46098214
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 107.70192176, sen-loss: 27.86364841, dom-loss: 79.83827353, train-acc: 0.90928571, val-acc: 0.91250000 val_loss: 0.28439060, dom-acc: 0.44401786
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 107.53256685, sen-loss: 27.34995557, dom-loss: 80.18261147, train-acc: 0.91357143, val-acc: 0.90500000 val_loss: 0.28687122, dom-acc: 0.41535714
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 107.21988124, sen-loss: 26.74345054, dom-loss: 80.47643054, train-acc: 0.90928571, val-acc: 0.90500000 val_loss: 0.30068648, dom-acc: 0.40562500
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.54842132, sen-loss: 26.29969983, dom-loss: 80.24872184, train-acc: 0.91517857, val-acc: 0.91750000 val_loss: 0.27643171, dom-acc: 0.42946429
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 105.83453566, sen-loss: 25.82927014, dom-loss: 80.00526571, train-acc: 0.91785714, val-acc: 0.91750000 val_loss: 0.28013489, dom-acc: 0.42223214
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.15419495, sen-loss: 25.58389025, dom-loss: 79.57030451, train-acc: 0.91892857, val-acc: 0.92000000 val_loss: 0.27712661, dom-acc: 0.45428571
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 103.79516846, sen-loss: 25.02073871, dom-loss: 78.77442998, train-acc: 0.92053571, val-acc: 0.91750000 val_loss: 0.27815279, dom-acc: 0.45937500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 102.97191787, sen-loss: 24.84459756, dom-loss: 78.12731993, train-acc: 0.92000000, val-acc: 0.92250000 val_loss: 0.27042541, dom-acc: 0.48937500
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 102.09740251, sen-loss: 24.39471698, dom-loss: 77.70268542, train-acc: 0.92142857, val-acc: 0.92500000 val_loss: 0.26968461, dom-acc: 0.51000000
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.19342512, sen-loss: 24.14022564, dom-loss: 77.05319929, train-acc: 0.92321429, val-acc: 0.92000000 val_loss: 0.27273503, dom-acc: 0.51151786
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 100.35331333, sen-loss: 23.78622153, dom-loss: 76.56709188, train-acc: 0.92500000, val-acc: 0.91750000 val_loss: 0.27664179, dom-acc: 0.52223214
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 99.69635755, sen-loss: 23.49623430, dom-loss: 76.20012313, train-acc: 0.92428571, val-acc: 0.92250000 val_loss: 0.28172588, dom-acc: 0.52991071
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 99.31377888, sen-loss: 23.26935215, dom-loss: 76.04442674, train-acc: 0.92625000, val-acc: 0.92250000 val_loss: 0.27951315, dom-acc: 0.52750000
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 99.33351803, sen-loss: 23.10850080, dom-loss: 76.22501695, train-acc: 0.92785714, val-acc: 0.92250000 val_loss: 0.27399519, dom-acc: 0.53214286
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_video_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.26968461
Testing accuracy: 0.83700000
./work/attentions/kitchen_video_train.txt
./work/pivots/kitchen_video_pos.txt
./work/pivots/kitchen_video_neg.txt
./work/attentions/kitchen_video_test.txt
loading data...
source domain:  video target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 9750
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 36180 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.43508077, sen-loss: 76.72117436, dom-loss: 82.71390653, train-acc: 0.72035714, val-acc: 0.72500000 val_loss: 0.65240115, dom-acc: 0.69258929
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 146.25804162, sen-loss: 69.25681496, dom-loss: 77.00122660, train-acc: 0.74321429, val-acc: 0.72500000 val_loss: 0.58349824, dom-acc: 0.76437500
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 135.25647235, sen-loss: 59.42539299, dom-loss: 75.83107907, train-acc: 0.80250000, val-acc: 0.78000000 val_loss: 0.49077126, dom-acc: 0.78071429
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 124.91137666, sen-loss: 49.56572852, dom-loss: 75.34564775, train-acc: 0.84517857, val-acc: 0.82750000 val_loss: 0.41215056, dom-acc: 0.79026786
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 117.66405296, sen-loss: 42.32479106, dom-loss: 75.33926183, train-acc: 0.86696429, val-acc: 0.85000000 val_loss: 0.36525974, dom-acc: 0.76964286
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.96346390, sen-loss: 37.17770751, dom-loss: 74.78575677, train-acc: 0.88446429, val-acc: 0.87750000 val_loss: 0.33116779, dom-acc: 0.76660714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 109.42096084, sen-loss: 34.57891710, dom-loss: 74.84204364, train-acc: 0.88232143, val-acc: 0.86750000 val_loss: 0.32743737, dom-acc: 0.74151786
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 108.19043553, sen-loss: 33.31014153, dom-loss: 74.88029385, train-acc: 0.89178571, val-acc: 0.87750000 val_loss: 0.31359765, dom-acc: 0.72705357
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 107.21819729, sen-loss: 32.38700508, dom-loss: 74.83119184, train-acc: 0.89875000, val-acc: 0.88250000 val_loss: 0.30857661, dom-acc: 0.71205357
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 106.31684202, sen-loss: 31.24465451, dom-loss: 75.07218790, train-acc: 0.90142857, val-acc: 0.88500000 val_loss: 0.30258864, dom-acc: 0.70535714
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 105.54295969, sen-loss: 30.38205169, dom-loss: 75.16090804, train-acc: 0.90321429, val-acc: 0.88750000 val_loss: 0.29982257, dom-acc: 0.68571429
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 105.49026728, sen-loss: 29.85611200, dom-loss: 75.63415509, train-acc: 0.90535714, val-acc: 0.88750000 val_loss: 0.29690927, dom-acc: 0.67696429
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 104.81960517, sen-loss: 29.07107309, dom-loss: 75.74853235, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.29661831, dom-acc: 0.65419643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 104.77334762, sen-loss: 28.51927829, dom-loss: 76.25406945, train-acc: 0.91267857, val-acc: 0.89500000 val_loss: 0.29604089, dom-acc: 0.63839286
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 104.52121407, sen-loss: 27.95216872, dom-loss: 76.56904519, train-acc: 0.91285714, val-acc: 0.89750000 val_loss: 0.28916359, dom-acc: 0.62875000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 104.82893980, sen-loss: 28.07850426, dom-loss: 76.75043547, train-acc: 0.91410714, val-acc: 0.89000000 val_loss: 0.29436675, dom-acc: 0.62071429
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 104.24728322, sen-loss: 27.10229690, dom-loss: 77.14498603, train-acc: 0.91696429, val-acc: 0.89500000 val_loss: 0.28568193, dom-acc: 0.60339286
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 104.50277489, sen-loss: 26.93400371, dom-loss: 77.56877118, train-acc: 0.91839286, val-acc: 0.89500000 val_loss: 0.28378403, dom-acc: 0.59669643
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 104.33361548, sen-loss: 26.45038052, dom-loss: 77.88323474, train-acc: 0.91964286, val-acc: 0.90000000 val_loss: 0.28257218, dom-acc: 0.58794643
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 103.96418077, sen-loss: 25.91468001, dom-loss: 78.04950052, train-acc: 0.91678571, val-acc: 0.89500000 val_loss: 0.28031477, dom-acc: 0.58035714
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.71499115, sen-loss: 25.56754182, dom-loss: 78.14744943, train-acc: 0.92125000, val-acc: 0.89750000 val_loss: 0.28449839, dom-acc: 0.56928571
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.88565093, sen-loss: 25.32141323, dom-loss: 78.56423777, train-acc: 0.92392857, val-acc: 0.90000000 val_loss: 0.28007182, dom-acc: 0.56312500
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 103.42168474, sen-loss: 24.86167267, dom-loss: 78.56001174, train-acc: 0.92482143, val-acc: 0.90000000 val_loss: 0.27821541, dom-acc: 0.55383929
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 103.42833006, sen-loss: 24.57439961, dom-loss: 78.85393047, train-acc: 0.92535714, val-acc: 0.90000000 val_loss: 0.28258976, dom-acc: 0.54160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.11322600, sen-loss: 24.28061367, dom-loss: 78.83261222, train-acc: 0.92660714, val-acc: 0.89750000 val_loss: 0.27649763, dom-acc: 0.54910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.68626517, sen-loss: 23.89680111, dom-loss: 78.78946447, train-acc: 0.92625000, val-acc: 0.90000000 val_loss: 0.28405765, dom-acc: 0.53446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.58219731, sen-loss: 23.67610423, dom-loss: 78.90609282, train-acc: 0.92678571, val-acc: 0.90250000 val_loss: 0.28477392, dom-acc: 0.53696429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.24276984, sen-loss: 23.36427819, dom-loss: 78.87849140, train-acc: 0.92892857, val-acc: 0.89750000 val_loss: 0.28208074, dom-acc: 0.53062500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.98902667, sen-loss: 23.13752633, dom-loss: 78.85150057, train-acc: 0.92946429, val-acc: 0.89500000 val_loss: 0.27670008, dom-acc: 0.53821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.57673723, sen-loss: 22.80461176, dom-loss: 78.77212512, train-acc: 0.93178571, val-acc: 0.89750000 val_loss: 0.27814817, dom-acc: 0.52142857
---------------------------------------------------

Successfully load model from save path: ./work/models/video_books_PNet.ckpt
Best Epoch: [ 25] best val accuracy: 0.00000000 best val loss: 0.27649763
Testing accuracy: 0.86816667
./work/attentions/video_books_train.txt
./work/pivots/video_books_pos.txt
./work/pivots/video_books_neg.txt
./work/attentions/video_books_test.txt
loading data...
source domain:  video target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 11843
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 36180 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.74616778, sen-loss: 76.69244957, dom-loss: 83.05371839, train-acc: 0.72357143, val-acc: 0.72250000 val_loss: 0.65095228, dom-acc: 0.57464286
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 148.10195947, sen-loss: 69.15725392, dom-loss: 78.94470567, train-acc: 0.74428571, val-acc: 0.73250000 val_loss: 0.58052003, dom-acc: 0.57357143
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 138.02672029, sen-loss: 59.18351990, dom-loss: 78.84320015, train-acc: 0.80625000, val-acc: 0.78250000 val_loss: 0.48675224, dom-acc: 0.58848214
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 128.01986063, sen-loss: 49.24595731, dom-loss: 78.77390319, train-acc: 0.84482143, val-acc: 0.84500000 val_loss: 0.40818691, dom-acc: 0.58919643
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 120.62331265, sen-loss: 41.91630307, dom-loss: 78.70700932, train-acc: 0.87017857, val-acc: 0.84750000 val_loss: 0.36259022, dom-acc: 0.56562500
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 115.40687954, sen-loss: 36.80519155, dom-loss: 78.60168785, train-acc: 0.88857143, val-acc: 0.87000000 val_loss: 0.33169156, dom-acc: 0.54151786
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 112.91549122, sen-loss: 34.34294271, dom-loss: 78.57254869, train-acc: 0.88517857, val-acc: 0.86750000 val_loss: 0.32920596, dom-acc: 0.59875000
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 111.64118302, sen-loss: 33.12833102, dom-loss: 78.51285166, train-acc: 0.89428571, val-acc: 0.87750000 val_loss: 0.31511283, dom-acc: 0.54375000
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.68655705, sen-loss: 32.22895849, dom-loss: 78.45759857, train-acc: 0.89964286, val-acc: 0.88250000 val_loss: 0.31044149, dom-acc: 0.59848214
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.49494964, sen-loss: 31.07996644, dom-loss: 78.41498327, train-acc: 0.90214286, val-acc: 0.89000000 val_loss: 0.30423841, dom-acc: 0.57169643
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.64907372, sen-loss: 30.23152386, dom-loss: 78.41755044, train-acc: 0.90428571, val-acc: 0.88750000 val_loss: 0.30164465, dom-acc: 0.56767857
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.06157792, sen-loss: 29.71810644, dom-loss: 78.34347171, train-acc: 0.90767857, val-acc: 0.89000000 val_loss: 0.29855716, dom-acc: 0.56642857
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 107.24954700, sen-loss: 28.93412667, dom-loss: 78.31542069, train-acc: 0.91232143, val-acc: 0.89000000 val_loss: 0.29783720, dom-acc: 0.59017857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.64477539, sen-loss: 28.41909997, dom-loss: 78.22567534, train-acc: 0.91303571, val-acc: 0.88750000 val_loss: 0.29774928, dom-acc: 0.59410714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.07993400, sen-loss: 27.84476401, dom-loss: 78.23516989, train-acc: 0.91392857, val-acc: 0.89000000 val_loss: 0.29012626, dom-acc: 0.60848214
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 106.11294633, sen-loss: 27.96482858, dom-loss: 78.14811772, train-acc: 0.91607143, val-acc: 0.88750000 val_loss: 0.29437965, dom-acc: 0.61803571
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 105.20111680, sen-loss: 27.01448582, dom-loss: 78.18663114, train-acc: 0.91732143, val-acc: 0.89250000 val_loss: 0.28636703, dom-acc: 0.56839286
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 105.08122563, sen-loss: 26.85375736, dom-loss: 78.22746789, train-acc: 0.91821429, val-acc: 0.89500000 val_loss: 0.28433049, dom-acc: 0.56473214
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 104.47522527, sen-loss: 26.36929072, dom-loss: 78.10593456, train-acc: 0.91875000, val-acc: 0.89750000 val_loss: 0.28243276, dom-acc: 0.55616071
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 103.89827347, sen-loss: 25.83858611, dom-loss: 78.05968744, train-acc: 0.91857143, val-acc: 0.89250000 val_loss: 0.28005251, dom-acc: 0.59696429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.52316737, sen-loss: 25.47705255, dom-loss: 78.04611474, train-acc: 0.92232143, val-acc: 0.89000000 val_loss: 0.28333569, dom-acc: 0.57616071
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.34777725, sen-loss: 25.24530786, dom-loss: 78.10246980, train-acc: 0.92464286, val-acc: 0.89250000 val_loss: 0.27973244, dom-acc: 0.54848214
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.79093957, sen-loss: 24.78083827, dom-loss: 78.01010120, train-acc: 0.92428571, val-acc: 0.89500000 val_loss: 0.27701020, dom-acc: 0.61544643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.52271169, sen-loss: 24.48650263, dom-loss: 78.03620881, train-acc: 0.92464286, val-acc: 0.89500000 val_loss: 0.28151065, dom-acc: 0.54241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.19537121, sen-loss: 24.20873172, dom-loss: 77.98663956, train-acc: 0.92607143, val-acc: 0.89500000 val_loss: 0.27459332, dom-acc: 0.56982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.78937203, sen-loss: 23.81564905, dom-loss: 77.97372317, train-acc: 0.92607143, val-acc: 0.89750000 val_loss: 0.28204864, dom-acc: 0.57410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.52697033, sen-loss: 23.60106964, dom-loss: 77.92590111, train-acc: 0.92625000, val-acc: 0.89750000 val_loss: 0.28247964, dom-acc: 0.60750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.25542760, sen-loss: 23.28560401, dom-loss: 77.96982342, train-acc: 0.92910714, val-acc: 0.89500000 val_loss: 0.27916640, dom-acc: 0.59937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.97788060, sen-loss: 23.06989449, dom-loss: 77.90798604, train-acc: 0.93053571, val-acc: 0.88750000 val_loss: 0.27369124, dom-acc: 0.54785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.64206946, sen-loss: 22.73015139, dom-loss: 77.91191816, train-acc: 0.93232143, val-acc: 0.89500000 val_loss: 0.27596685, dom-acc: 0.54616071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.32972383, sen-loss: 22.48049673, dom-loss: 77.84922659, train-acc: 0.93250000, val-acc: 0.89750000 val_loss: 0.27859643, dom-acc: 0.51964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.01213449, sen-loss: 22.07764746, dom-loss: 77.93448699, train-acc: 0.93517857, val-acc: 0.89250000 val_loss: 0.27111813, dom-acc: 0.51285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.70870042, sen-loss: 21.82331204, dom-loss: 77.88538855, train-acc: 0.93642857, val-acc: 0.90000000 val_loss: 0.27179420, dom-acc: 0.53169643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.43223614, sen-loss: 21.60770002, dom-loss: 77.82453638, train-acc: 0.93821429, val-acc: 0.89750000 val_loss: 0.27617779, dom-acc: 0.56848214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.03521699, sen-loss: 21.15862300, dom-loss: 77.87659425, train-acc: 0.93089286, val-acc: 0.89000000 val_loss: 0.27672857, dom-acc: 0.55383929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 98.92945415, sen-loss: 21.08753098, dom-loss: 77.84192312, train-acc: 0.93875000, val-acc: 0.89500000 val_loss: 0.27160650, dom-acc: 0.56196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 98.42019641, sen-loss: 20.64972687, dom-loss: 77.77046955, train-acc: 0.94000000, val-acc: 0.89750000 val_loss: 0.27299377, dom-acc: 0.57267857
---------------------------------------------------

Successfully load model from save path: ./work/models/video_dvd_PNet.ckpt
Best Epoch: [ 32] best val accuracy: 0.00000000 best val loss: 0.27111813
Testing accuracy: 0.87366667
./work/attentions/video_dvd_train.txt
./work/pivots/video_dvd_pos.txt
./work/pivots/video_dvd_neg.txt
./work/attentions/video_dvd_test.txt
loading data...
source domain:  video target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 17009
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 36180 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.62167144, sen-loss: 76.72450727, dom-loss: 82.89716411, train-acc: 0.72142857, val-acc: 0.72500000 val_loss: 0.65184677, dom-acc: 0.77544643
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 144.45616019, sen-loss: 69.38188696, dom-loss: 75.07427341, train-acc: 0.74125000, val-acc: 0.71750000 val_loss: 0.58343327, dom-acc: 0.82464286
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 131.78560579, sen-loss: 59.80694696, dom-loss: 71.97865927, train-acc: 0.80178571, val-acc: 0.77500000 val_loss: 0.49247313, dom-acc: 0.70366071
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 120.98254400, sen-loss: 50.28975254, dom-loss: 70.69279170, train-acc: 0.84160714, val-acc: 0.83500000 val_loss: 0.41802120, dom-acc: 0.60589286
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.33584261, sen-loss: 43.26865453, dom-loss: 72.06718808, train-acc: 0.86196429, val-acc: 0.85250000 val_loss: 0.37288204, dom-acc: 0.57571429
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 110.79147291, sen-loss: 37.95071152, dom-loss: 72.84076160, train-acc: 0.88392857, val-acc: 0.87000000 val_loss: 0.33471364, dom-acc: 0.57205357
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 109.08502913, sen-loss: 35.12336321, dom-loss: 73.96166569, train-acc: 0.88089286, val-acc: 0.87000000 val_loss: 0.33126587, dom-acc: 0.56866071
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 108.57539934, sen-loss: 33.77955954, dom-loss: 74.79584002, train-acc: 0.88857143, val-acc: 0.87500000 val_loss: 0.31494135, dom-acc: 0.54517857
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 108.54364622, sen-loss: 32.82918747, dom-loss: 75.71445918, train-acc: 0.89642857, val-acc: 0.88250000 val_loss: 0.31141877, dom-acc: 0.51517857
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 108.21139210, sen-loss: 31.64381374, dom-loss: 76.56757843, train-acc: 0.89982143, val-acc: 0.88000000 val_loss: 0.30380952, dom-acc: 0.48241071
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 107.98373204, sen-loss: 30.73791195, dom-loss: 77.24582028, train-acc: 0.90142857, val-acc: 0.88500000 val_loss: 0.30063507, dom-acc: 0.46008929
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.19991821, sen-loss: 30.20042743, dom-loss: 77.99949068, train-acc: 0.90500000, val-acc: 0.89250000 val_loss: 0.29822248, dom-acc: 0.44482143
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.09740365, sen-loss: 29.39573467, dom-loss: 78.70166892, train-acc: 0.90964286, val-acc: 0.88500000 val_loss: 0.29783741, dom-acc: 0.43812500
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 107.66615713, sen-loss: 28.84619471, dom-loss: 78.81996238, train-acc: 0.90946429, val-acc: 0.88500000 val_loss: 0.29744720, dom-acc: 0.43473214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.96192884, sen-loss: 28.25476778, dom-loss: 78.70716077, train-acc: 0.91357143, val-acc: 0.89500000 val_loss: 0.28963205, dom-acc: 0.42616071
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 107.44382083, sen-loss: 28.38117878, dom-loss: 79.06264216, train-acc: 0.91160714, val-acc: 0.88750000 val_loss: 0.29538098, dom-acc: 0.43267857
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 106.31033063, sen-loss: 27.38666023, dom-loss: 78.92367035, train-acc: 0.91732143, val-acc: 0.89500000 val_loss: 0.28548694, dom-acc: 0.43562500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 105.79912859, sen-loss: 27.20544543, dom-loss: 78.59368283, train-acc: 0.91750000, val-acc: 0.90000000 val_loss: 0.28296769, dom-acc: 0.42705357
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 105.10426223, sen-loss: 26.74015556, dom-loss: 78.36410654, train-acc: 0.92035714, val-acc: 0.90000000 val_loss: 0.28200063, dom-acc: 0.42785714
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 104.47186881, sen-loss: 26.17745718, dom-loss: 78.29441184, train-acc: 0.91839286, val-acc: 0.89250000 val_loss: 0.27876297, dom-acc: 0.44000000
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.88612902, sen-loss: 25.83152039, dom-loss: 78.05460846, train-acc: 0.92017857, val-acc: 0.89750000 val_loss: 0.28324798, dom-acc: 0.44214286
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.49291044, sen-loss: 25.58234794, dom-loss: 77.91056252, train-acc: 0.92339286, val-acc: 0.90250000 val_loss: 0.27820694, dom-acc: 0.44473214
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.75493306, sen-loss: 25.10450540, dom-loss: 77.65042752, train-acc: 0.92392857, val-acc: 0.89750000 val_loss: 0.27625719, dom-acc: 0.44705357
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.18817157, sen-loss: 24.81627937, dom-loss: 77.37189221, train-acc: 0.92053571, val-acc: 0.90000000 val_loss: 0.28161889, dom-acc: 0.44303571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.94077367, sen-loss: 24.55317561, dom-loss: 77.38759828, train-acc: 0.92625000, val-acc: 0.89500000 val_loss: 0.27360877, dom-acc: 0.44937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.05483729, sen-loss: 24.14621267, dom-loss: 76.90862429, train-acc: 0.92375000, val-acc: 0.90250000 val_loss: 0.28305838, dom-acc: 0.44089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.26124603, sen-loss: 23.93917798, dom-loss: 77.32206815, train-acc: 0.92446429, val-acc: 0.90500000 val_loss: 0.28232232, dom-acc: 0.46000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 100.69032067, sen-loss: 23.63078086, dom-loss: 77.05953979, train-acc: 0.92678571, val-acc: 0.90250000 val_loss: 0.28001344, dom-acc: 0.45089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.36704338, sen-loss: 23.41052531, dom-loss: 76.95651799, train-acc: 0.93053571, val-acc: 0.89500000 val_loss: 0.27236488, dom-acc: 0.45982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 99.96688312, sen-loss: 23.06292102, dom-loss: 76.90396190, train-acc: 0.93125000, val-acc: 0.90500000 val_loss: 0.27569890, dom-acc: 0.46401786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 99.53904641, sen-loss: 22.81022996, dom-loss: 76.72881651, train-acc: 0.93196429, val-acc: 0.90250000 val_loss: 0.27922124, dom-acc: 0.46214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 98.84202462, sen-loss: 22.42409486, dom-loss: 76.41793031, train-acc: 0.93250000, val-acc: 0.90250000 val_loss: 0.27015796, dom-acc: 0.47464286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 98.47252834, sen-loss: 22.15815008, dom-loss: 76.31437796, train-acc: 0.93267857, val-acc: 0.89250000 val_loss: 0.27046117, dom-acc: 0.48026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 98.45399505, sen-loss: 21.94757234, dom-loss: 76.50642264, train-acc: 0.93625000, val-acc: 0.90250000 val_loss: 0.27618471, dom-acc: 0.48151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 97.80889404, sen-loss: 21.50195447, dom-loss: 76.30693948, train-acc: 0.93035714, val-acc: 0.87750000 val_loss: 0.27384076, dom-acc: 0.49383929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 97.86613059, sen-loss: 21.41395608, dom-loss: 76.45217448, train-acc: 0.93892857, val-acc: 0.89750000 val_loss: 0.27012154, dom-acc: 0.48196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 97.44198430, sen-loss: 20.99633626, dom-loss: 76.44564784, train-acc: 0.93875000, val-acc: 0.90000000 val_loss: 0.27236640, dom-acc: 0.48812500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 96.92012042, sen-loss: 20.54405450, dom-loss: 76.37606597, train-acc: 0.93696429, val-acc: 0.88500000 val_loss: 0.27158335, dom-acc: 0.48437500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 96.78164315, sen-loss: 20.29657830, dom-loss: 76.48506492, train-acc: 0.94142857, val-acc: 0.90000000 val_loss: 0.27753118, dom-acc: 0.47973214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 96.91115457, sen-loss: 20.14015795, dom-loss: 76.77099663, train-acc: 0.94375000, val-acc: 0.90000000 val_loss: 0.27652165, dom-acc: 0.47151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 96.70982081, sen-loss: 19.82351165, dom-loss: 76.88630903, train-acc: 0.94535714, val-acc: 0.90000000 val_loss: 0.27771103, dom-acc: 0.47008929
---------------------------------------------------

Successfully load model from save path: ./work/models/video_electronics_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.27012154
Testing accuracy: 0.83466667
./work/attentions/video_electronics_train.txt
./work/pivots/video_electronics_pos.txt
./work/pivots/video_electronics_neg.txt
./work/attentions/video_electronics_test.txt
loading data...
source domain:  video target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 13856
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 36180 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.32281971, sen-loss: 76.74809092, dom-loss: 82.57472903, train-acc: 0.72250000, val-acc: 0.72000000 val_loss: 0.65204102, dom-acc: 0.78687500
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 144.54545784, sen-loss: 69.28513664, dom-loss: 75.26032114, train-acc: 0.73910714, val-acc: 0.70250000 val_loss: 0.58374369, dom-acc: 0.88633929
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 132.85538578, sen-loss: 59.48662823, dom-loss: 73.36875802, train-acc: 0.80464286, val-acc: 0.77500000 val_loss: 0.49202043, dom-acc: 0.88473214
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 122.61700284, sen-loss: 49.63453555, dom-loss: 72.98246700, train-acc: 0.84678571, val-acc: 0.84000000 val_loss: 0.41542503, dom-acc: 0.82205357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.94595039, sen-loss: 42.25473714, dom-loss: 73.69121313, train-acc: 0.86714286, val-acc: 0.85500000 val_loss: 0.36739570, dom-acc: 0.76794643
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.86083299, sen-loss: 37.12294567, dom-loss: 74.73788679, train-acc: 0.88446429, val-acc: 0.87750000 val_loss: 0.33280951, dom-acc: 0.72821429
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.45262867, sen-loss: 34.61828579, dom-loss: 75.83434278, train-acc: 0.88107143, val-acc: 0.86750000 val_loss: 0.33004844, dom-acc: 0.70241071
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.43101025, sen-loss: 33.39894168, dom-loss: 77.03206855, train-acc: 0.89267857, val-acc: 0.87750000 val_loss: 0.31513703, dom-acc: 0.67901786
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.46166700, sen-loss: 32.51926497, dom-loss: 77.94240206, train-acc: 0.90017857, val-acc: 0.88000000 val_loss: 0.31042102, dom-acc: 0.59553571
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.18993509, sen-loss: 31.35616079, dom-loss: 78.83377469, train-acc: 0.89946429, val-acc: 0.88750000 val_loss: 0.30408636, dom-acc: 0.56026786
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 109.95354533, sen-loss: 30.50773408, dom-loss: 79.44581091, train-acc: 0.90107143, val-acc: 0.89000000 val_loss: 0.30114532, dom-acc: 0.50187500
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.02710235, sen-loss: 29.99856883, dom-loss: 80.02853352, train-acc: 0.90625000, val-acc: 0.88750000 val_loss: 0.29812613, dom-acc: 0.49401786
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 109.49610299, sen-loss: 29.20246061, dom-loss: 80.29364252, train-acc: 0.90892857, val-acc: 0.88500000 val_loss: 0.29730499, dom-acc: 0.46250000
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.89189190, sen-loss: 28.65995689, dom-loss: 80.23193461, train-acc: 0.91214286, val-acc: 0.88250000 val_loss: 0.29734781, dom-acc: 0.46687500
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 108.35276800, sen-loss: 28.11314406, dom-loss: 80.23962396, train-acc: 0.91125000, val-acc: 0.89500000 val_loss: 0.28972065, dom-acc: 0.46901786
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.12486833, sen-loss: 28.22715931, dom-loss: 79.89770925, train-acc: 0.91232143, val-acc: 0.88750000 val_loss: 0.29448873, dom-acc: 0.48321429
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 106.71019906, sen-loss: 27.26578590, dom-loss: 79.44441348, train-acc: 0.91500000, val-acc: 0.89250000 val_loss: 0.28604972, dom-acc: 0.48491071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 106.25010580, sen-loss: 27.11757959, dom-loss: 79.13252640, train-acc: 0.91732143, val-acc: 0.89500000 val_loss: 0.28380248, dom-acc: 0.50187500
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 105.11317718, sen-loss: 26.63894003, dom-loss: 78.47423702, train-acc: 0.91821429, val-acc: 0.89750000 val_loss: 0.28249288, dom-acc: 0.51678571
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 104.11444402, sen-loss: 26.09587926, dom-loss: 78.01856512, train-acc: 0.91517857, val-acc: 0.89250000 val_loss: 0.28021026, dom-acc: 0.52526786
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.37530875, sen-loss: 25.75527042, dom-loss: 77.62003857, train-acc: 0.91982143, val-acc: 0.89750000 val_loss: 0.28355056, dom-acc: 0.55348214
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 102.80658787, sen-loss: 25.54008301, dom-loss: 77.26650476, train-acc: 0.92339286, val-acc: 0.89750000 val_loss: 0.27962881, dom-acc: 0.52392857
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.17375809, sen-loss: 25.06170627, dom-loss: 77.11205220, train-acc: 0.92464286, val-acc: 0.89250000 val_loss: 0.27734220, dom-acc: 0.52419643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 101.78442401, sen-loss: 24.77073049, dom-loss: 77.01369303, train-acc: 0.92214286, val-acc: 0.89750000 val_loss: 0.28207952, dom-acc: 0.51205357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.46639985, sen-loss: 24.50019577, dom-loss: 76.96620387, train-acc: 0.92571429, val-acc: 0.89000000 val_loss: 0.27479297, dom-acc: 0.51392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.21469772, sen-loss: 24.09806588, dom-loss: 77.11663181, train-acc: 0.92464286, val-acc: 0.89750000 val_loss: 0.28211927, dom-acc: 0.49526786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.11171901, sen-loss: 23.89267864, dom-loss: 77.21904081, train-acc: 0.92410714, val-acc: 0.90250000 val_loss: 0.28271815, dom-acc: 0.51133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.01684785, sen-loss: 23.57647442, dom-loss: 77.44037348, train-acc: 0.92803571, val-acc: 0.89500000 val_loss: 0.27977628, dom-acc: 0.49151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.97175944, sen-loss: 23.35626545, dom-loss: 77.61549383, train-acc: 0.92696429, val-acc: 0.89250000 val_loss: 0.27352625, dom-acc: 0.48750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.54218870, sen-loss: 23.00689980, dom-loss: 77.53528887, train-acc: 0.93196429, val-acc: 0.89250000 val_loss: 0.27514991, dom-acc: 0.47455357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.45859140, sen-loss: 22.75803070, dom-loss: 77.70056069, train-acc: 0.93000000, val-acc: 0.90000000 val_loss: 0.27933714, dom-acc: 0.46964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.01970488, sen-loss: 22.37722430, dom-loss: 77.64248031, train-acc: 0.93214286, val-acc: 0.89000000 val_loss: 0.27086180, dom-acc: 0.47919643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.76699281, sen-loss: 22.12082876, dom-loss: 77.64616388, train-acc: 0.93250000, val-acc: 0.89000000 val_loss: 0.27164516, dom-acc: 0.48535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.49976152, sen-loss: 21.91102535, dom-loss: 77.58873588, train-acc: 0.93625000, val-acc: 0.89500000 val_loss: 0.27560598, dom-acc: 0.48366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.03222144, sen-loss: 21.46992563, dom-loss: 77.56229603, train-acc: 0.93089286, val-acc: 0.88750000 val_loss: 0.27485171, dom-acc: 0.49482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 98.93481380, sen-loss: 21.37245179, dom-loss: 77.56236172, train-acc: 0.93767857, val-acc: 0.88750000 val_loss: 0.27095923, dom-acc: 0.51098214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 98.34119672, sen-loss: 20.93597571, dom-loss: 77.40522110, train-acc: 0.93785714, val-acc: 0.89000000 val_loss: 0.27269509, dom-acc: 0.52125000
---------------------------------------------------

Successfully load model from save path: ./work/models/video_kitchen_PNet.ckpt
Best Epoch: [ 32] best val accuracy: 0.00000000 best val loss: 0.27086180
Testing accuracy: 0.84633333
./work/attentions/video_kitchen_train.txt
./work/pivots/video_kitchen_pos.txt
./work/pivots/video_kitchen_neg.txt
./work/attentions/video_kitchen_test.txt
